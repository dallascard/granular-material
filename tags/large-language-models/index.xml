<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large-Language-Models on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/large-language-models/</link><description>Recent content in Large-Language-Models on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 29 Sep 2024 16:51:57 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Bespoke Navigation</title><link>https://dallascard.github.io/granular-material/post/bespoke-navigation/</link><pubDate>Sun, 29 Sep 2024 16:51:57 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/bespoke-navigation/</guid><description>&lt;p>I don&amp;rsquo;t normally do this, but I recently did a short bike trip in Michigan, and I thought I would write a brief post about it, in part because it cued various other ideas which have a more direct connection to the kinds of things I normally write about here.&lt;/p></description></item><item><title>Credible Estimates and Open Science</title><link>https://dallascard.github.io/granular-material/post/blair-institute/</link><pubDate>Tue, 30 Jul 2024 20:18:44 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/blair-institute/</guid><description>&lt;p>Somewhere on social media I encountered the recent story that the &lt;a href="https://www.institute.global/">Tony Blair Institute for Global Change&lt;/a>, (a large, avowedly centrist think tank created by Tony Blair), put out a &lt;a href="https://web.archive.org/web/20240709092248/https://assets.ctfassets.net/75ila1cntaeh/45YsrTDwevNRvsTsZ5dZGS/fc9805fa3a5a1de3c931d0446dcec239/Tony_Blair_Institute_for_Global_Change__The_Potential_Impact_of_AI_on_the_Public-Sector_Workforce__July_2024.pdf">report&lt;/a> estimating the potential impact of AI on jobs in the public service, but that ironically, they arrived at their estimates by basically just asking GPT-4. While this does have a certain kind of poetry to it, it&amp;rsquo;s not exactly what we think of as a reputable methodology.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p></description></item><item><title>Financing Common Crawl</title><link>https://dallascard.github.io/granular-material/post/financing-common-crawl/</link><pubDate>Sun, 31 Mar 2024 20:08:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/financing-common-crawl/</guid><description>Mozilla recently published an excellent new report out about Common Crawl, the non-profit whose web crawls have played an important role in the development of numerous large language models (LLMs). Written by Stefan Baack and Mozilla Insights, the report is based on both public documents and new interviews with Common Crawl&amp;rsquo;s current director and crawl engineer, and goes into some detail about the history of the organization, and how its data is being used.</description></item><item><title>ChatGPT Prompt Speculations</title><link>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</link><pubDate>Thu, 22 Feb 2024 10:00:26 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</guid><description>In a recent tweet that went viral, Dylan Patel claimed to have discovered or revealed the ChatGPT prompt, using a simple hack. The tweet included a link to a text file on pastebin and a screenshot of that same text with newlines removed. More interestingly, the author suggested in a reply that anyone could replicate this finding, and a subsequent tweet included a video of ChatGPT generating text in response to the same trick. That, however, is where things get somewhat strange.</description></item><item><title>Infinitely Wide Culture</title><link>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</link><pubDate>Sun, 28 Jan 2024 15:59:40 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</guid><description>&lt;p>A lot of this is still unresolved in my mind, but I think there is something interesting happening at the intersection of generative AI, art, style, and entertainment. Rather than letting it gestate until more fully formed, I figured I&amp;rsquo;d just post some preliminary thoughts and come back to this at some later date.&lt;/p>
&lt;p>The main reason I&amp;rsquo;m thinking about this now is the ongoing debate about how generative AI will impact creative fields, such as writing and design (as well as white collar jobs more broadly). Arguably there have already been some pretty dramatic effects, such as the sci-fi magazine &lt;em>Clarkesworld&lt;/em> being &lt;a href="https://neil-clarke.com/a-concerning-trend/">suddenly overwhelmed&lt;/a> by spammy submissions. At the same time, it&amp;rsquo;s hard to know the extent to which these disruptions may end up being transient phenomena that broader systems will adapt to.&lt;/p></description></item><item><title>Ubi Sunt</title><link>https://dallascard.github.io/granular-material/post/ubi_sunt/</link><pubDate>Sun, 17 Sep 2023 13:05:18 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/ubi_sunt/</guid><description>&lt;p>There is a duality at the heart of large language models. On the one hand, they are essentially a backwards-looking invention, a &lt;a href="https://www.youtube.com/live/k7rPtFLH6yw?si=bD6ir6cwtpOtEV0i">&amp;ldquo;cultural technology&amp;rdquo;&lt;/a>, in the words of Alison Gopnik&amp;mdash;algorithms which index and remix a large slice of human culture (though one that is typically heavily biased towards the recent past). On the other hand, they can often seem to be producing something entirely new, and can thereby leave many people with the impression of having a personality or even &amp;ldquo;sentience&amp;rdquo; (whatever that means exactly); in the most extreme cases, &lt;a href="https://youtu.be/NgHFMolXs3U?si=gfKBPeOlEhQeDdEg">some people&lt;/a> have apparently convinced themselves that such models are a step on the path towards some sort of successor species to humanity, a new regime of algorithmic children that will survive our own human catastrophes. Complicating matters here is the fact that the emergence of and widespread attention to these systems largely overlapped with the Covid-19 pandemic, a time in which we have all had additional reason to reflect on life, death, loss, and creation.&lt;/p></description></item><item><title>University of Michigan's New AI Tools</title><link>https://dallascard.github.io/granular-material/post/michigan-gpt/</link><pubDate>Mon, 28 Aug 2023 21:04:19 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/michigan-gpt/</guid><description>Just before the start of the fall semester, the University of Michigan announced that it was launching a new suite of tools, all focused on &amp;ldquo;generative AI&amp;rdquo;, (although so far limited to language models), which will be available to all students, faculty, and staff. This post provides a preliminary exploration of the new offerings.</description></item><item><title>ChatGPT Hobbyists</title><link>https://dallascard.github.io/granular-material/post/mcgee/</link><pubDate>Mon, 29 May 2023 10:42:43 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/mcgee/</guid><description>&lt;p>ChatGPT has understandably garnered a huge amount of attention from all corners of academia, from philosophy to economics. One of the more quixotic examples I&amp;rsquo;ve encountered recently is &lt;a href="https://www.robertwmcgee.com/about/">Robert W. McGee&lt;/a>, and his many papers on this topic, such as &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4359405">&amp;ldquo;Is Chat Gpt Biased Against Conservatives? An Empirical Study&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>A professor of accounting at Fayetteville University, McGee&amp;rsquo;s biography reads as something like a Marvel Cinematic Universe version of a nerdy academic supervillain. In addition to having published 59 non-fiction books, McGee apparently holds 23 academic degrees, including 13 doctorates, as well as being a world champion in various martial arts, such as Taekwondo and Tai Chi.&lt;/p></description></item><item><title>Samsung's Encounter with ChatGPT</title><link>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</link><pubDate>Thu, 13 Apr 2023 19:48:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</guid><description>&lt;p>As ChatGPT continues to ricochet through the news cycle, media outlets are surely on the hunt for new angles they can present to the public in order to keep this story in motion. Among other threads, one that has gained some traction is the question of risks to privacy and security presented by these new systems.&lt;/p>
&lt;p>Last week, a number of US outlets &lt;a href="https://mashable.com/article/samsung-chatgpt-leak-details">reported&lt;/a> on data leaks at Samsung, in which three employees (in separate incidents) apparently entered confidential company information into ChatGPT. According to &lt;a href="https://www.engadget.com/three-samsung-employees-reportedly-leaked-sensitive-data-to-chatgpt-190221114.html">reports&lt;/a>, in one case, an employee tried using ChatGPT to help debug code, another to optimize code, and a third to have it produce a summary of meeting notes.&lt;/p></description></item><item><title>ChatGPT and Sociotechnical Instability</title><link>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</link><pubDate>Sun, 19 Feb 2023 13:04:13 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</guid><description>&lt;p>I&amp;rsquo;ve written about this &lt;a href="https://dallascard.github.io/granular-material/post/stability/">before&lt;/a>, but it&amp;rsquo;s worth remembering that almost nothing in sociotechnical systems is guaranteed to remain stable for very long. We&amp;rsquo;ve recently had two great examples of this, with the first being the changes to Twitter, and the second being ChatGPT (and, by extension, the new Bing).&lt;/p>
&lt;p>In the first case, a platform which had long seemed relatively static, (especially compared to all the rest), rather suddenly changed hands, which led to major changes in what it delivered. On some level, many of the technical changes to the actual functionality of the site were relatively minor. Much bigger, however, was the impact of many people abandoning the platform for alternatives like Mastodon. Although it seems to me like people have gradually been filtering back to Twitter, most people seem to have the sense that the experience has changed. Obviously more dramatic infrastructural changes, like prioritizing tweets from paying users, could produce even more dramatic shifts. Regardless, it&amp;rsquo;s a good reminder that what we think of as &amp;ldquo;Twitter&amp;rdquo; is the product of a combination of people and software, either or both of which can shift dramatically in a short period of time.&lt;/p></description></item><item><title>ChatGPT Dominance</title><link>https://dallascard.github.io/granular-material/post/chatgpt-dominance/</link><pubDate>Sat, 21 Jan 2023 14:39:35 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt-dominance/</guid><description>&lt;p>I expect that almost anyone reading this will have heard of ChatGPT by now. Released about a month ago, ChatGPT is a system developed by OpenAI which provides text responses to text input. Although details are scarce, under the hood ChatGPT is basically a large language model, trained with some additional tricks (see Yoav Goldberg&amp;rsquo;s &lt;a href="https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9">write up&lt;/a> for a good summary). In other words, it is a model which maps from the text input (treated as a sequence of tokens), to a distribution over possible next tokens, and generates text by making repeated calls to this function, and sampling tokens from the predicted distributions.&lt;/p></description></item><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item><item><title>Hacking LLM bots</title><link>https://dallascard.github.io/granular-material/post/remote-work-bot/</link><pubDate>Fri, 23 Sep 2022 10:39:28 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/remote-work-bot/</guid><description>&lt;p>For anyone who missed it, a Twitter account named @mkualquiera recently deployed what seems like a kind of adversarial attack in the wild on a large language model (LLM)-based Twitter bot. I&amp;rsquo;ll link to the key post below, but it&amp;rsquo;s worth providing a bit of context, as it wasn&amp;rsquo;t immediately clear to me what was going on when I first saw the tweet.&lt;/p>
&lt;figure>&lt;img src="../../img/remote-work-bot/header.png">
&lt;/figure></description></item><item><title>Report from FAccT 2022</title><link>https://dallascard.github.io/granular-material/post/facct-2022/</link><pubDate>Sun, 03 Jul 2022 12:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/facct-2022/</guid><description>The fifth iteration of FAccT (the ACM Conference on Fairness, Accountability, and Transparency) was held earlier this month (June 21–24) in Seoul, South Korea. More than just a hybrid conference, this was actually a full in-person conference, combined with a full on-line conference. These happened in parallel, with virtual sessions starting before and continuing after the in-person component each day. Around 500 people attended in person, with another 500 participating remotely.</description></item></channel></rss>