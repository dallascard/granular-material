<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Optical-Character-Recognition on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/optical-character-recognition/</link><description>Recent content in Optical-Character-Recognition on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 27 May 2024 12:52:46 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/optical-character-recognition/index.xml" rel="self" type="application/rss+xml"/><item><title>The OpenAI Library</title><link>https://dallascard.github.io/granular-material/post/openai-library/</link><pubDate>Mon, 27 May 2024 12:52:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/openai-library/</guid><description>The New York Times recently ran a brief article about the reading room in OpenAI&amp;rsquo;s office in San Francisco. The article was heavy on images and light on text, but the overall theme was the tension between the company&amp;rsquo;s GPT models&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->which have been trained on vast swaths of human culture, and are therefore able to regurgitate, remix, and approximate it&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->versus embracing the design and aesthetic trappings of a traditional library reading room. The article mentioned a handful of books that could be found in the OpenAI library, but many more were clearly visible in the photographs that accompanied it.</description></item></channel></rss>