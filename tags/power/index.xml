<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>power on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/power/</link><description>Recent content in power on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 12 Dec 2022 18:48:06 -0500</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/power/index.xml" rel="self" type="application/rss+xml"/><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item><item><title>Representational Power</title><link>https://dallascard.github.io/granular-material/post/representational-power/</link><pubDate>Sat, 20 Jul 2019 21:27:37 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/representational-power/</guid><description>&lt;figure>&lt;a href="https://en.wikipedia.org/wiki/View_from_the_Window_at_Le_Gras">&lt;img src="../../img/representational-power//plate.jpeg"
alt="The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827."/>&lt;/a>&lt;figcaption>
&lt;p>The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827.&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>Although it isn’t normally thought of in these terms, taking a photograph involves recording a four-dimensional block of space-time and projecting it down to a two-dimensional representation. With sufficiently sensitive material (and a fast enough shutter), one can produce images more or less instantaneously, but longer exposures reveal the inherent temporality of this process, showing us something that is clearly based on the world, yet quite different from our experience of it. Today, the ability to create images is so commonplace, of course, that we easily take it for granted, but early commentaries on photography reveal just how extraordinary it once was. Indeed, the history of photography provides both a compelling example of the power of representation, and a useful parallel to more recent forms of technological magic, especially that of machine learning.&lt;/p></description></item></channel></rss>