<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Digital-Preservation on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/digital-preservation/</link><description>Recent content in Digital-Preservation on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 31 Mar 2024 20:08:01 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/digital-preservation/index.xml" rel="self" type="application/rss+xml"/><item><title>Financing Common Crawl</title><link>https://dallascard.github.io/granular-material/post/financing-common-crawl/</link><pubDate>Sun, 31 Mar 2024 20:08:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/financing-common-crawl/</guid><description>Mozilla recently published an excellent new report out about Common Crawl, the non-profit whose web scrapes have played an important role in the development of numerous large language models (LLMs). Written by Stefan Baack and Mozilla Insights, the report is based on both public documents and new interviews with Common Crawl&amp;rsquo;s current director and crawl engineer, and goes into some detail about the history of the organization, and how its data is being used.</description></item><item><title>Ubi Sunt</title><link>https://dallascard.github.io/granular-material/post/ubi_sunt/</link><pubDate>Sun, 17 Sep 2023 13:05:18 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/ubi_sunt/</guid><description>There is a duality at the heart of large language models. On the one hand, they are essentially a backwards-looking invention, a &amp;ldquo;cultural technology&amp;rdquo;, in the words of Alison Gopnik&amp;mdash;algorithms which index and remix a large slice of human culture (though one that is typically heavily biased towards the recent past). On the other hand, they can often seem to be producing something entirely new, and can thereby leave many people with the impression of having a personality or even &amp;ldquo;sentience&amp;rdquo; (whatever that means exactly); in the most extreme cases, some people have apparently convinced themselves that such models are a step on the path towards some sort of successor species to humanity, a new regime of algorithmic children that will survive our own human catastrophes.</description></item><item><title>Reproducibility in Art and Science</title><link>https://dallascard.github.io/granular-material/post/reproducibility-in-art-and-science/</link><pubDate>Mon, 05 Jun 2017 20:43:20 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/reproducibility-in-art-and-science/</guid><description>Marking the beginning of a new partnership between Rhizome and the Google Cultural Institute, the Rhizome blog recently published a conversation between Dragan Espenschied, Rhizome’s preservation director, and Vint Cerf, Google’s Chief Internet Evangelist. In addition to bringing together two people with among the coolest job titles ever, it got me thinking about some similarities between art and science when it comes to the issue of reproduction.
The main thrust of the conversation is about the difficulty of preserving internet art.</description></item></channel></rss>