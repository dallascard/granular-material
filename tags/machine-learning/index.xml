<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine-learning on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/machine-learning/</link><description>Recent content in machine-learning on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Fri, 23 Sep 2022 10:39:28 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Hacking LLM bots</title><link>https://dallascard.github.io/granular-material/post/remote-work-bot/</link><pubDate>Fri, 23 Sep 2022 10:39:28 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/remote-work-bot/</guid><description>For anyone who missed it, a Twitter account named @mkualquiera recently deployed what seems like a kind of adversarial attack in the wild on a large language model (LLM)-based Twitter bot. I&amp;rsquo;ll link to the key post below, but it&amp;rsquo;s worth providing a bit of context, as it wasn&amp;rsquo;t immediately clear to me what was going on when I first saw the tweet.
The bot itself (@remoteli_io) claims it &amp;ldquo;helps you discover remote jobs which allow you to work from anywhere&amp;rdquo;.</description></item><item><title>Report from FAccT 2022</title><link>https://dallascard.github.io/granular-material/post/facct-2022/</link><pubDate>Sun, 03 Jul 2022 12:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/facct-2022/</guid><description>The fifth iteration of FAccT (the ACM Conference on Fairness, Accountability, and Transparency) was held earlier this month (June 21–24) in Seoul, South Korea. More than just a hybrid conference, this was actually a full in-person conference, combined with a full on-line conference. These happened in parallel, with virtual sessions starting before and continuing after the in-person component each day. Around 500 people attended in person, with another 500 participating remotely.</description></item><item><title>Modular Domain Adaptation</title><link>https://dallascard.github.io/granular-material/post/modular/</link><pubDate>Mon, 25 Apr 2022 20:16:54 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/modular/</guid><description>Despite their limitations, off-the-shelf models are still quite widely used by computational social science researchers for measuring various properties of text, including both lexicons, like LIWC, and cloud-based APIs, like Perspective API. The approach of using an off-the-shelf model has some definite advantages, including standardization and reproducibility, but such models may not be reliable when applied to a domain that differs from the ones on which they were developed&amp;hellip;</description></item><item><title>Confidence in Science</title><link>https://dallascard.github.io/granular-material/post/confidence-in-science/</link><pubDate>Sun, 06 Mar 2022 09:20:14 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/confidence-in-science/</guid><description>I’ve been thinking recently about the role of confidence in science, and how long beliefs can persist simply because everyone else seems to believe them. Coincidentally, Andrew Gelman posted about this two days ago, responding to comments from a biologist about how the replication crisis had not been a major problem in biology. Her argument was that this was because biology is a &amp;ldquo;cumulative science&amp;rdquo;. By this she meant that when something important gets published, it is often the kind of discovery that people want to use immediately.</description></item><item><title>AI Dermatology: Part 2</title><link>https://dallascard.github.io/granular-material/post/ai-dermatology-2/</link><pubDate>Sat, 19 Feb 2022 16:26:43 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-dermatology-2/</guid><description>​In the last post, I discussed the possible broader implications of Google&amp;rsquo;s recent foray into making an AI dermatology tool. In this follow up post, I want to focus on the research behind the product announcement, bringing a slightly critical eye.</description></item><item><title>AI Dermatology: Part 1</title><link>https://dallascard.github.io/granular-material/post/ai-dermatology-1/</link><pubDate>Sat, 05 Feb 2022 07:32:51 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-dermatology-1/</guid><description>Midway through last year Google announced a new foray into the medical technology space, sharing that it was developing an &amp;ldquo;AI-powered dermatology assist tool&amp;rdquo;&amp;mdash;a phone-based app that would allow users to take photos of skin lesions and retrieve information about relevant medical conditions from the web. Similar apps already exist, but it&amp;rsquo;s fair to say that a comparable effort by Google is likely to have much more significant effects on how people interact with the medical system, their personal data, and even their own bodies.</description></item><item><title>Representational Power</title><link>https://dallascard.github.io/granular-material/post/representational-power/</link><pubDate>Sat, 20 Jul 2019 21:27:37 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/representational-power/</guid><description>&lt;figure>&lt;a href="https://en.wikipedia.org/wiki/View_from_the_Window_at_Le_Gras">&lt;img src="../../img/representational-power//plate.jpeg"
alt="The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827."/>&lt;/a>&lt;figcaption>
&lt;p>The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827.&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>Although it isn’t normally thought of in these terms, taking a photograph involves recording a four-dimensional block of space-time and projecting it down to a two-dimensional representation. With sufficiently sensitive material (and a fast enough shutter), one can produce images more or less instantaneously, but longer exposures reveal the inherent temporality of this process, showing us something that is clearly based on the world, yet quite different from our experience of it. Today, the ability to create images is so commonplace, of course, that we easily take it for granted, but early commentaries on photography reveal just how extraordinary it once was. Indeed, the history of photography provides both a compelling example of the power of representation, and a useful parallel to more recent forms of technological magic, especially that of machine learning.&lt;/p></description></item><item><title>On the Perils of Automated Face Recognition</title><link>https://dallascard.github.io/granular-material/post/face-recognition/</link><pubDate>Mon, 17 Dec 2018 21:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/face-recognition/</guid><description>&lt;figure>&lt;a href="https://commons.wikimedia.org/wiki/File:Bertillon,_Alphonse,_fiche_anthropom%C3%A9trique_recto-verso.jpg">&lt;img src="../../img/face-recognition/bertillon.jpeg"
alt="Anthropometric data sheet (both sides) of Alphonse Bertillon (1853–1914)."/>&lt;/a>&lt;figcaption>
&lt;p>Anthropometric data sheet (both sides) of Alphonse Bertillon (1853–1914).&lt;/p>
&lt;/figcaption>
&lt;/figure>
&lt;p>For anyone who has been paying attention, it will not have gone unnoticed that the past year has seen a dramatic expansion in the use of face recognition technology, including at schools, border crossing, and interactions with the police. Most recently, &lt;a href="https://news.delta.com/delta-unveils-first-biometric-terminal-us-atlanta-next-stop-detroit">Delta announced&lt;/a> that some passengers in Atlanta will be able to check in and go through security using only their face as identification. Most news coverage of this announcement emphasized the supposed convenience, efficiency, and technical novelty, while underplaying any potential hazards. In fact, however, the combination of widely available images, the ability to build on existing infrastructure, and a legal landscape that places very few restrictions on recording, means that face recognition represents a unique threat to privacy that should concern us greatly.&lt;/p></description></item><item><title>What everyone needs to know about interpretability in machine learning</title><link>https://dallascard.github.io/granular-material/post/interpretability/</link><pubDate>Fri, 25 May 2018 20:46:57 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/interpretability/</guid><description>For anyone who’s been paying attention, it should be apparent that statistical machine learning systems are being widely deployed for automated decision making in all kinds of areas these days, including criminal justice, medicine, education, employment, policing, and so on. Particularly with the recently enacted GDPR&amp;mdash;the new European regulation about data and privacy&amp;mdash;there is growing interest in having systems that are interpretable, that is, we can make some sense of why they are making the prediction that they are making. To borrow an example from Been Kim, if a computer tells you that you need surgery, you’re probably going to ask for some sort of explanation.</description></item></channel></rss>