<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Augmented-Reality-Games on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/augmented-reality-games/</link><description>Recent content in Augmented-Reality-Games on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 22 Feb 2024 10:00:26 -0500</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/augmented-reality-games/index.xml" rel="self" type="application/rss+xml"/><item><title>ChatGPT Prompt Speculations</title><link>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</link><pubDate>Thu, 22 Feb 2024 10:00:26 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</guid><description>In a recent tweet that went viral, Dylan Patel claimed to have discovered or revealed the ChatGPT prompt, using a simple hack. The tweet included a link to a text file on pastebin and a screenshot of that same text with newlines removed. More interestingly, the author suggested in a reply that anyone could replicate this finding, and a subsequent tweet included a video of ChatGPT generating text in response to the same trick. That, however, is where things get somewhat strange.</description></item></channel></rss>