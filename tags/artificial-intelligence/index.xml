<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Artificial-Intelligence on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/artificial-intelligence/</link><description>Recent content in Artificial-Intelligence on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 24 Mar 2025 13:09:22 -0500</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/artificial-intelligence/index.xml" rel="self" type="application/rss+xml"/><item><title>Markets for Content</title><link>https://dallascard.github.io/granular-material/post/markets_for_content/</link><pubDate>Mon, 24 Mar 2025 13:09:22 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/markets_for_content/</guid><description>I don&amp;rsquo;t carefully track the numbers, bit it seems like various sectors of the media have been hit hard by layoffs recently. Earlier this month, Disney announced that it was shuttering FiveThirtyEight, the data journalism outlet that Nate Silver started what now feels like a lifetime ago. According to the Wall Street Journal, FiveThirtyEight only had a staff of about 15 people, but the move is part of a broader consolidation and job cuts at the company.</description></item><item><title>Chatbot Roulette</title><link>https://dallascard.github.io/granular-material/post/freysa/</link><pubDate>Sun, 08 Dec 2024 22:07:15 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/freysa/</guid><description>&lt;p>There was some excitement online recently around &lt;a href="https://x.com/jarrodWattsDev/status/1862299845710757980">&amp;ldquo;Freysa&amp;rdquo;&lt;/a>, a contest which combined large language models (LLMs) with some sort of blockchain technology. The basic idea was for participants to interact with an LLM to try to get it to do a thing that it had been instructed not to do. The trick was that the cost of each attempt increased after every submission (up to some maximum), as did the potential reward.&lt;/p></description></item><item><title>Sociotechnical Considerations</title><link>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</link><pubDate>Sat, 27 Apr 2024 13:42:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</guid><description>&lt;p>A whole genre of podcasts seems to have emerged recently, taking the shape of interviews with CEOs of AI companies, or similar. Although I have not listened to many of these, they mostly seem to be pretty abysmal, both because of the amount of hype they involve, and due to the lack of meaningful specifics.&lt;/p>
&lt;p>That being said, of the ones I&amp;rsquo;ve heard, the recent &lt;a href="https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html">interview with Dario Amodei of Anthropic on the Ezra Klein Show&lt;/a> seems to me to be vastly better than the average. In part, this is because Klein is a smart, curious, and well informed interviewer, who asks a lot of the right questions, and pushes for details when responses get too mushy. In this case, it also helps that Amodei seems much more straightforwardly honest about limitations than most spokespeople in similar positions.&lt;/p></description></item><item><title>Refik Anadol</title><link>https://dallascard.github.io/granular-material/post/refik-anadol/</link><pubDate>Wed, 25 Oct 2023 11:05:12 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/refik-anadol/</guid><description>&lt;p>Last week&amp;rsquo;s speaker in the &lt;a href="https://stamps.umich.edu/penny-stamps-speaker-series">Penny Stamps Speaker Series&lt;/a> was &lt;a href="https://en.wikipedia.org/wiki/Refik_Anadol">Refik Anadol&lt;/a>, one of the most successful artists working primarily with AI, data, and visualization. Over a decade or so, Anadol has produced work in collaboration with organizations and venues like the &lt;a href="https://refikanadol.com/works/visions-of-america-ameriques/">LA Philharmonic&lt;/a>, Gaudi&amp;rsquo;s &lt;a href="https://refikanadol.com/works/living-architecture-casa-batllo/">Casa BatllÃ³&lt;/a>, &lt;a href="https://refikanadol.com/works/machine-hallucinations-sphere/">the Exosphere&lt;/a> in Las Vegas, and &lt;a href="https://refikanadol.com/works/unsupervised/">the Museum of Modern Art&lt;/a> in New York.&lt;/p>
&lt;p>The lecture he gave was basically a review of his body of work, and that of his art and design studio, which is comprised of about 20 people. The earlier projects he showed mostly took the form of massive scale &lt;a href="https://refikanadol.com/works/quadrature/">light projections&lt;/a> on the sides of buildings, which could give the impression of a totally different texture or form. More recent work tended to use data driven visualizations, abstracting some sort of data into visual patterns displayed on a wall, building, or screen. Many of these also made use of what appeared to be procedural animations to create the impression of three dimensionality and motion.&lt;/p></description></item><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item></channel></rss>