<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Openai on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/openai/</link><description>Recent content in Openai on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 30 Jul 2024 20:18:44 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/openai/index.xml" rel="self" type="application/rss+xml"/><item><title>Credible Estimates and Open Science</title><link>https://dallascard.github.io/granular-material/post/blair-institute/</link><pubDate>Tue, 30 Jul 2024 20:18:44 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/blair-institute/</guid><description>&lt;p>Somewhere on social media I encountered the recent story that the &lt;a href="https://www.institute.global/">Tony Blair Institute for Global Change&lt;/a>, (a large, avowedly centrist think tank created by Tony Blair), put out a &lt;a href="https://web.archive.org/web/20240709092248/https://assets.ctfassets.net/75ila1cntaeh/45YsrTDwevNRvsTsZ5dZGS/fc9805fa3a5a1de3c931d0446dcec239/Tony_Blair_Institute_for_Global_Change__The_Potential_Impact_of_AI_on_the_Public-Sector_Workforce__July_2024.pdf">report&lt;/a> estimating the potential impact of AI on jobs in the public service, but that ironically, they arrived at their estimates by basically just asking GPT-4. While this does have a certain kind of poetry to it, it&amp;rsquo;s not exactly what we think of as a reputable methodology.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p></description></item><item><title>The OpenAI Library</title><link>https://dallascard.github.io/granular-material/post/openai-library/</link><pubDate>Mon, 27 May 2024 12:52:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/openai-library/</guid><description>The New York Times recently ran a brief article about the reading room in OpenAI&amp;rsquo;s office in San Francisco. The article was heavy on images and light on text, but the overall theme was the tension between the company&amp;rsquo;s GPT models&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->which have been trained on vast swaths of human culture, and are therefore able to regurgitate, remix, and approximate it&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->versus embracing the design and aesthetic trappings of a traditional library reading room. The article mentioned a handful of books that could be found in the OpenAI library, but many more were clearly visible in the photographs that accompanied it.</description></item></channel></rss>