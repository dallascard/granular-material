<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Wayback-Machine on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/wayback-machine/</link><description>Recent content in Wayback-Machine on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 31 Mar 2024 20:08:01 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/wayback-machine/index.xml" rel="self" type="application/rss+xml"/><item><title>Financing Common Crawl</title><link>https://dallascard.github.io/granular-material/post/financing-common-crawl/</link><pubDate>Sun, 31 Mar 2024 20:08:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/financing-common-crawl/</guid><description>Mozilla recently published an excellent new report out about Common Crawl, the non-profit whose web crawls have played an important role in the development of numerous large language models (LLMs). Written by Stefan Baack and Mozilla Insights, the report is based on both public documents and new interviews with Common Crawl&amp;rsquo;s current director and crawl engineer, and goes into some detail about the history of the organization, and how its data is being used.</description></item></channel></rss>