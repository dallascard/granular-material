<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Security on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/security/</link><description>Recent content in Security on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 13 Apr 2023 19:48:46 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/security/index.xml" rel="self" type="application/rss+xml"/><item><title>Samsung's Encounter with ChatGPT</title><link>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</link><pubDate>Thu, 13 Apr 2023 19:48:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</guid><description>As ChatGPT continues to ricochet through the news cycle, media outlets are surely on the hunt for new angles they can present to the public in order to keep this story in motion. Among other threads, one that has gained some traction is the question of risks to privacy and security presented by these new systems.
Last week, a number of US outlets reported on data leaks at Samsung, in which three employees (in separate incidents) apparently entered confidential company information into ChatGPT.</description></item></channel></rss>