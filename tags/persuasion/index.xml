<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Persuasion on Granular Material</title><generator uri="https://gohugo.io">Hugo</generator><link>https://dallascard.github.io/granular-material/tags/persuasion/</link><language>en-us</language><updated>Sun, 08 Dec 2024 22:07:15 -0500</updated><item><title>A review I recently wrote that I expect to write again</title><link>https://dallascard.github.io/granular-material/post/llm-review-excerpt/</link><pubDate>Mon, 22 Dec 2025 15:19:45 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/llm-review-excerpt/</guid><description>We are at a strange moment in scholarship, where a powerful new tool (language models) has been handed to people, and existing academic systems are scrambling to figure out how to respond. Even leaving aside the crisis around a potential deluge of AI-generated papers, there are many more conventional questions about what an appropriate use of language models is for domains other than computer science. Especially in the social sciences, my understanding is that established journals are struggling both to recruit qualified reviewers, and to know what appropriate standards should be, in terms of methodological rigor.</description></item><item><title>Language Model Hacking</title><link>https://dallascard.github.io/granular-material/post/language-model-hacking/</link><pubDate>Wed, 12 Nov 2025 17:24:13 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/language-model-hacking/</guid><description>&lt;p&gt;With the widespread success of language models on many tasks in a zero-shot setting, there has been a huge surge of interest among social scientists in wanting to use them to code or classify documents, sometimes in place of human annotators. Given both the freedom to specify prompts, and the lack of connection to domain-specific training data, a concern naturally arises as to how easily people can manipulate their designs to produce a desired conclusion. This had been on my mind recently, and so I was delighted to see that a couple of recent papers specifically take on this question, both of which conclude that there is indeed considerable latitude to produce a desired finding by manipulating the choices involved. These are extremely useful and important results, although they also open up some questions for me, which I wanted to think through here.&lt;/p&gt;</description></item><item><title>Why Write?</title><link>https://dallascard.github.io/granular-material/post/why-write/</link><pubDate>Mon, 01 Sep 2025 16:22:27 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/why-write/</guid><description>&lt;p&gt;If there is one question that I have returned to over and over in various hand-written journals, it is the basic question of why write anything at all. This could be taken to be asking myself why I am writing, or why others choose to write, or what the purpose or point of writing is more broadly. It could be a question about motivation, or impacts, or addiction. It could be a provocation, to myself or others. But the mystery remains. Why engage in this dangerous business?&lt;/p&gt;</description></item><item><title>About</title><link>https://dallascard.github.io/granular-material/about/</link><pubDate>Fri, 01 Aug 2025 16:42:18 +0400</pubDate><guid>https://dallascard.github.io/granular-material/about/</guid><description>&lt;p&gt;This blog is about exploring topics related to science, technology, and culture in slightly more detail than is reasonable. Written by &lt;a href="https://dallascard.github.io"&gt;Dallas Card&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Posts typically appear about once a month. If you would like to follow along, please use the &lt;a href="https://dallascard.github.io/granular-material//index.xml"&gt;RSS feed&lt;/a&gt; (also linked below).&lt;/p&gt;</description></item><item><title>Peeping Tom, Triptych</title><link>https://dallascard.github.io/granular-material/post/triptych/</link><pubDate>Fri, 28 Mar 2025 23:55:54 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/triptych/</guid><description>I don&amp;rsquo;t go to see much in the way of contemporary dance, but on a whim, I decided to get tickets to the Power Center to see &lt;em&gt;Triptych&lt;/em&gt;, a performance developed by the Peeping Tom dance company from Belgium. Comprised of three pieces&amp;mdash;&lt;em&gt;The Missing Door&lt;/em&gt;, &lt;em&gt;The Lost Room&lt;/em&gt; and &lt;em&gt;The Hidden Floor&lt;/em&gt;&amp;mdash;created in 2013, 2015, and 2017, respectively, the performance ran just over two hours, including a partial intermission. This post is a bit of a break from what I&amp;rsquo;ve been writing lately, but it feels worth highlighting, if only to help keep at least some attention on artistic endeavours. Just as a warning, I have not refrained from spoiling anything in here, so you might want to stop reading if you&amp;rsquo;re planning to see it and want the full effect.</description></item><item><title>Markets for Content</title><link>https://dallascard.github.io/granular-material/post/markets_for_content/</link><pubDate>Mon, 24 Mar 2025 13:09:22 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/markets_for_content/</guid><description>I don&amp;rsquo;t carefully track the numbers, bit it seems like various sectors of the media have been hit hard by layoffs recently. Earlier this month, Disney announced that it was shuttering FiveThirtyEight, the data journalism outlet that Nate Silver started what now feels like a lifetime ago. According to the Wall Street Journal, FiveThirtyEight only had a staff of about 15 people, but the move is part of a broader consolidation and job cuts at the company.</description></item><item><title>Force of Law</title><link>https://dallascard.github.io/granular-material/post/force-of-law/</link><pubDate>Mon, 10 Feb 2025 23:42:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/force-of-law/</guid><description>I do not feel particularly well qualified to write about this, but it seems to me that recent events have dramatically and urgently gestured at the nature of the rule of law, and the tenuousness of reliable enforcement. Since coming into office, the new administration has been carrying out actions that many legal experts suggest are illegal. In several cases since then, judges have issued orders which demand a pause on particular actions. Most recently, the New York Times reports that a judge has now ruled that the White House has failed to comply with a court order. While less splashy than various overt actions, this kind of failure act seems to me like to very close to the red line suggested by various commentators, including conservatives.</description></item><item><title>Chatbot Roulette</title><link>https://dallascard.github.io/granular-material/post/freysa/</link><pubDate>Sun, 08 Dec 2024 22:07:15 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/freysa/</guid><description>&lt;p&gt;There was some excitement online recently around &lt;a href="https://x.com/jarrodWattsDev/status/1862299845710757980"&gt;&amp;ldquo;Freysa&amp;rdquo;&lt;/a&gt;, a contest which combined large language models (LLMs) with some sort of blockchain technology. The basic idea was for participants to interact with an LLM to try to get it to do a thing that it had been instructed not to do. The trick was that the cost of each attempt increased after every submission (up to some maximum), as did the potential reward.&lt;/p&gt;</description></item><item><title>What is a Podcast?</title><link>https://dallascard.github.io/granular-material/post/sporc/</link><pubDate>Sat, 16 Nov 2024 19:34:55 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/sporc/</guid><description>What is a podcast? I expect we all have our own slightly idiosyncratic answer to that question. For me, podcasts are defined partly by some software I use on my phone that regularly downloads audio files from various feeds, which I periodically listen to, often as I&amp;rsquo;m doing other things. Most of these recordings feature two or more people engaged in a long-form conversation. Some of these take the form of interviews, in which a regular host interviews a rotating series of guests. Others feature rotating subsets of the same group of hosts, talking together about various issues. A few shows, like Hardcore History, are just long monologues, not so different from an audiobook.</description></item><item><title>Bespoke Navigation</title><link>https://dallascard.github.io/granular-material/post/bespoke-navigation/</link><pubDate>Sun, 29 Sep 2024 16:51:57 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/bespoke-navigation/</guid><description>&lt;p&gt;I don&amp;rsquo;t normally do this, but I recently did a short bike trip in Michigan, and I thought I would write a brief post about it, in part because it cued various other ideas which have a more direct connection to the kinds of things I normally write about here.&lt;/p&gt;</description></item><item><title>Credible Estimates and Open Science</title><link>https://dallascard.github.io/granular-material/post/blair-institute/</link><pubDate>Tue, 30 Jul 2024 20:18:44 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/blair-institute/</guid><description>&lt;p&gt;Somewhere on social media I encountered the recent story that the &lt;a href="https://www.institute.global/"&gt;Tony Blair Institute for Global Change&lt;/a&gt;, (a large, avowedly centrist think tank created by Tony Blair), put out a &lt;a href="https://web.archive.org/web/20240709092248/https://assets.ctfassets.net/75ila1cntaeh/45YsrTDwevNRvsTsZ5dZGS/fc9805fa3a5a1de3c931d0446dcec239/Tony_Blair_Institute_for_Global_Change__The_Potential_Impact_of_AI_on_the_Public-Sector_Workforce__July_2024.pdf"&gt;report&lt;/a&gt; estimating the potential impact of AI on jobs in the public service, but that ironically, they arrived at their estimates by basically just asking GPT-4. While this does have a certain kind of poetry to it, it&amp;rsquo;s not exactly what we think of as a reputable methodology.&lt;sup id="fnref:1"&gt;&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;</description></item><item><title>Altair vs. Bokeh (part 3): Scatterplots</title><link>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_3/</link><pubDate>Sat, 22 Jun 2024 18:17:35 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_3/</guid><description>This is my third entry in a series comparing two interactive data visualization libraries for python, Bokeh and Altair. In part 1, I went through a basic overview of some of the differences in terms of syntactic style and defaults. In part 2, I went slightly deeper into some of the interactive features and more fundamental limitations. In this part, I want to deepen the comparison further, by exploring the basic capabilities each package offers with respect to a basic chart type, namely scatterplots.</description></item><item><title>The OpenAI Library</title><link>https://dallascard.github.io/granular-material/post/openai-library/</link><pubDate>Mon, 27 May 2024 12:52:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/openai-library/</guid><description>The New York Times recently ran a brief article about the reading room in OpenAI&amp;rsquo;s office in San Francisco. The article was heavy on images and light on text, but the overall theme was the tension between the company&amp;rsquo;s GPT models&lt;!-- raw HTML omitted --&gt;—&lt;!-- raw HTML omitted --&gt;which have been trained on vast swaths of human culture, and are therefore able to regurgitate, remix, and approximate it&lt;!-- raw HTML omitted --&gt;—&lt;!-- raw HTML omitted --&gt;versus embracing the design and aesthetic trappings of a traditional library reading room. The article mentioned a handful of books that could be found in the OpenAI library, but many more were clearly visible in the photographs that accompanied it.</description></item><item><title>Sociotechnical Considerations</title><link>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</link><pubDate>Sat, 27 Apr 2024 13:42:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</guid><description>&lt;p&gt;A whole genre of podcasts seems to have emerged recently, taking the shape of interviews with CEOs of AI companies, or similar. Although I have not listened to many of these, they mostly seem to be pretty abysmal, both because of the amount of hype they involve, and due to the lack of meaningful specifics.&lt;/p&gt;
&lt;p&gt;That being said, of the ones I&amp;rsquo;ve heard, the recent &lt;a href="https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html"&gt;interview with Dario Amodei of Anthropic on the Ezra Klein Show&lt;/a&gt; seems to me to be vastly better than the average. In part, this is because Klein is a smart, curious, and well informed interviewer, who asks a lot of the right questions, and pushes for details when responses get too mushy. In this case, it also helps that Amodei seems much more straightforwardly honest about limitations than most spokespeople in similar positions.&lt;/p&gt;</description></item><item><title>Financing Common Crawl</title><link>https://dallascard.github.io/granular-material/post/financing-common-crawl/</link><pubDate>Sun, 31 Mar 2024 20:08:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/financing-common-crawl/</guid><description>Mozilla recently published an excellent new report out about Common Crawl, the non-profit whose web crawls have played an important role in the development of numerous large language models (LLMs). Written by Stefan Baack and Mozilla Insights, the report is based on both public documents and new interviews with Common Crawl&amp;rsquo;s current director and crawl engineer, and goes into some detail about the history of the organization, and how its data is being used.</description></item></channel></rss>