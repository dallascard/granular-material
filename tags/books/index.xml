<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Books on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/books/</link><description>Recent content in Books on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 27 May 2024 12:52:46 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/books/index.xml" rel="self" type="application/rss+xml"/><item><title>The OpenAI Library</title><link>https://dallascard.github.io/granular-material/post/openai-library/</link><pubDate>Mon, 27 May 2024 12:52:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/openai-library/</guid><description>The New York Times recently ran a brief article about the reading room in OpenAI&amp;rsquo;s office in San Francisco. The article was heavy on images and light on text, but the overall theme was the tension between the company&amp;rsquo;s GPT models&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->which have been trained on vast swaths of human culture, and are therefore able to regurgitate, remix, and approximate it&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->versus embracing the design and aesthetic trappings of a traditional library reading room. The article mentioned a handful of books that could be found in the OpenAI library, but many more were clearly visible in the photographs that accompanied it.</description></item><item><title>Sociotechnical Considerations</title><link>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</link><pubDate>Sat, 27 Apr 2024 13:42:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</guid><description>A whole genre of podcasts seems to have emerged recently, taking the shape of interviews with CEOs of AI companies, or similar. Although I have not listened to many of these, they mostly seem to be pretty abysmal, both because of the amount of hype they involve, and due to the lack of meaningful specifics.
That being said, of the ones I&amp;rsquo;ve heard, the recent interview with Dario Amodei of Anthropic on the Ezra Klein Show seems to me to be vastly better than the average.</description></item><item><title>Infinitely Wide Culture</title><link>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</link><pubDate>Sun, 28 Jan 2024 15:59:40 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</guid><description>A lot of this is still unresolved in my mind, but I think there is something interesting happening at the intersection of generative AI, art, style, and entertainment. Rather than letting it gestate until more fully formed, I figured I&amp;rsquo;d just post some preliminary thoughts and come back to this at some later date.
The main reason I&amp;rsquo;m thinking about this now is the ongoing debate about how generative AI will impact creative fields, such as writing and design (as well as white collar jobs more broadly).</description></item><item><title>Tightly-woven Cultural Commentary</title><link>https://dallascard.github.io/granular-material/post/interwoven_commentary/</link><pubDate>Thu, 14 Dec 2023 21:57:32 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/interwoven_commentary/</guid><description>I recently started listening to the Art of the Score podcast, which does an amazing job of unpacking movie soundtracks in depth, beginning with Raiders of the Lost Ark in the first episode. Like most such explorations of music, however, it ultimately leaves me wanting something that I&amp;rsquo;ve long thought there should be much more of&amp;mdash;namely, more tightly interwoven cultural commentary, especially for music. As I will describe below, I&amp;rsquo;m broadly interested in different ways of combining context, commentary, and criticism with the thing being commented on or critiqued.</description></item><item><title>Ubi Sunt</title><link>https://dallascard.github.io/granular-material/post/ubi_sunt/</link><pubDate>Sun, 17 Sep 2023 13:05:18 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/ubi_sunt/</guid><description>There is a duality at the heart of large language models. On the one hand, they are essentially a backwards-looking invention, a &amp;ldquo;cultural technology&amp;rdquo;, in the words of Alison Gopnik&amp;mdash;algorithms which index and remix a large slice of human culture (though one that is typically heavily biased towards the recent past). On the other hand, they can often seem to be producing something entirely new, and can thereby leave many people with the impression of having a personality or even &amp;ldquo;sentience&amp;rdquo; (whatever that means exactly); in the most extreme cases, some people have apparently convinced themselves that such models are a step on the path towards some sort of successor species to humanity, a new regime of algorithmic children that will survive our own human catastrophes.</description></item><item><title>Privacy in Context</title><link>https://dallascard.github.io/granular-material/post/privacy-in-context/</link><pubDate>Mon, 14 May 2018 23:09:37 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/privacy-in-context/</guid><description>Although it was not the largest of its kind, or the most invasive, or even particularly surprising, the recent Cambridge Analytica scandal produced a surprisingly large amount of outrage and commentary. If nothing else, it was yet another reminder that we have gradually slipped into a regime where certain aspects of our privacy that could once be taken for granted are now long gone. Are people concerned? Is this something we should be worried about?</description></item><item><title>Elbow Room</title><link>https://dallascard.github.io/granular-material/post/elbow-room/</link><pubDate>Fri, 31 Mar 2017 20:52:03 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/elbow-room/</guid><description>&lt;figure>&lt;img src="../../img/elbow-room/thinker.jpeg">
&lt;/figure>

&lt;p>Daniel Dennett is one of the most fascinating philosophers currently living. Although he pursued a traditional (but nonetheless exceptional) course of education, over time he seems to have moved farther and farther away from traditional philosophical methods and styles, and more toward a form of engagement that is simultaneously rigorous, original, and accessible. Not only is he prolific, he is far better informed on scientific topics than any other philosopher I can think of, and seems to have quite intentionally pursued a course through the relevant fields of inquiry in order to develop a sophisticated understanding of what we are as human beings.&lt;/p></description></item></channel></rss>