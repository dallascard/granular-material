<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>software on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/software/</link><description>Recent content in software on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 12 Dec 2022 18:48:06 -0500</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/software/index.xml" rel="self" type="application/rss+xml"/><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item><item><title>Stability and Change</title><link>https://dallascard.github.io/granular-material/post/stability/</link><pubDate>Sat, 12 Mar 2022 17:40:34 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/stability/</guid><description>One of the biggest frustrations with software is that things are constantly changing. From operating systems to apps to web interfaces, things rarely remain the same for very long, especially for users of Windows or MacOS.
There are many reasons for this of course. For decades, hardware has continued to improve at a steady rate, and so software is constantly being rewritten to take advantage of the latest capabilities. Moreover, the incredibly sloppy standard for software quality and reliability (compared to traditional engineering disciplines) means that even the most professional software is shipped with massive numbers of bugs and vulnerabilities, which constantly need to be patched.</description></item></channel></rss>