<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>fiction on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/fiction/</link><description>Recent content in fiction on Granular Material</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 17 Sep 2023 13:05:18 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/fiction/index.xml" rel="self" type="application/rss+xml"/><item><title>Ubi Sunt</title><link>https://dallascard.github.io/granular-material/post/ubi_sunt/</link><pubDate>Sun, 17 Sep 2023 13:05:18 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/ubi_sunt/</guid><description>There is a duality at the heart of large language models. On the one hand, they are essentially a backwards-looking invention, a &amp;ldquo;cultural technology&amp;rdquo;, in the words of Alison Gopnik&amp;mdash;algorithms which index and remix a large slice of human culture (though one that is typically heavily biased towards the recent past). On the other hand, they can often seem to be producing something entirely new, and can thereby leave many people with the impression of having a personality or even &amp;ldquo;sentience&amp;rdquo; (whatever that means exactly); in the most extreme cases, some people have apparently convinced themselves that such models are a step on the path towards some sort of successor species to humanity, a new regime of algorithmic children that will survive our own human catastrophes.</description></item></channel></rss>