<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sociotechnical-Systems on Granular Material</title><link>https://dallascard.github.io/granular-material/tags/sociotechnical-systems/</link><description>Recent content in Sociotechnical-Systems on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 08 Dec 2024 22:07:15 -0500</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/tags/sociotechnical-systems/index.xml" rel="self" type="application/rss+xml"/><item><title>Chatbot Roulette</title><link>https://dallascard.github.io/granular-material/post/freysa/</link><pubDate>Sun, 08 Dec 2024 22:07:15 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/freysa/</guid><description>&lt;p>There was some excitement online recently around &lt;a href="https://x.com/jarrodWattsDev/status/1862299845710757980">&amp;ldquo;Freysa&amp;rdquo;&lt;/a>, a contest which combined large language models (LLMs) with some sort of blockchain technology. The basic idea was for participants to interact with an LLM to try to get it to do a thing that it had been instructed not to do. The trick was that the cost of each attempt increased after every submission (up to some maximum), as did the potential reward.&lt;/p></description></item><item><title>Sociotechnical Considerations</title><link>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</link><pubDate>Sat, 27 Apr 2024 13:42:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</guid><description>&lt;p>A whole genre of podcasts seems to have emerged recently, taking the shape of interviews with CEOs of AI companies, or similar. Although I have not listened to many of these, they mostly seem to be pretty abysmal, both because of the amount of hype they involve, and due to the lack of meaningful specifics.&lt;/p>
&lt;p>That being said, of the ones I&amp;rsquo;ve heard, the recent &lt;a href="https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html">interview with Dario Amodei of Anthropic on the Ezra Klein Show&lt;/a> seems to me to be vastly better than the average. In part, this is because Klein is a smart, curious, and well informed interviewer, who asks a lot of the right questions, and pushes for details when responses get too mushy. In this case, it also helps that Amodei seems much more straightforwardly honest about limitations than most spokespeople in similar positions.&lt;/p></description></item><item><title>The Gradual Disappearance of Twitter</title><link>https://dallascard.github.io/granular-material/post/twitter-immolation/</link><pubDate>Sun, 11 Jun 2023 10:42:43 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/twitter-immolation/</guid><description>&lt;p>It was &lt;a href="https://inews.co.uk/news/twitter-researchers-delete-data-unless-pay-2364535">recently reported&lt;/a> by inews.co.uk that Twitter is going to start charging academic researchers and institution $42,000/month if they want to maintain their current level of expansive access to data, and &amp;ndash; more significantly &amp;ndash; require that they delete all Twitter data from their archives if they do not. I&amp;rsquo;d heard rumors that this might be happening a few weeks ago, but the iNews article is the first independent reporting that I&amp;rsquo;ve seen about it.&lt;/p></description></item><item><title>ChatGPT Hobbyists</title><link>https://dallascard.github.io/granular-material/post/mcgee/</link><pubDate>Mon, 29 May 2023 10:42:43 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/mcgee/</guid><description>&lt;p>ChatGPT has understandably garnered a huge amount of attention from all corners of academia, from philosophy to economics. One of the more quixotic examples I&amp;rsquo;ve encountered recently is &lt;a href="https://www.robertwmcgee.com/about/">Robert W. McGee&lt;/a>, and his many papers on this topic, such as &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4359405">&amp;ldquo;Is Chat Gpt Biased Against Conservatives? An Empirical Study&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>A professor of accounting at Fayetteville University, McGee&amp;rsquo;s biography reads as something like a Marvel Cinematic Universe version of a nerdy academic supervillain. In addition to having published 59 non-fiction books, McGee apparently holds 23 academic degrees, including 13 doctorates, as well as being a world champion in various martial arts, such as Taekwondo and Tai Chi.&lt;/p></description></item><item><title>ChatGPT and Sociotechnical Instability</title><link>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</link><pubDate>Sun, 19 Feb 2023 13:04:13 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</guid><description>&lt;p>I&amp;rsquo;ve written about this &lt;a href="https://dallascard.github.io/granular-material/post/stability/">before&lt;/a>, but it&amp;rsquo;s worth remembering that almost nothing in sociotechnical systems is guaranteed to remain stable for very long. We&amp;rsquo;ve recently had two great examples of this, with the first being the changes to Twitter, and the second being ChatGPT (and, by extension, the new Bing).&lt;/p>
&lt;p>In the first case, a platform which had long seemed relatively static, (especially compared to all the rest), rather suddenly changed hands, which led to major changes in what it delivered. On some level, many of the technical changes to the actual functionality of the site were relatively minor. Much bigger, however, was the impact of many people abandoning the platform for alternatives like Mastodon. Although it seems to me like people have gradually been filtering back to Twitter, most people seem to have the sense that the experience has changed. Obviously more dramatic infrastructural changes, like prioritizing tweets from paying users, could produce even more dramatic shifts. Regardless, it&amp;rsquo;s a good reminder that what we think of as &amp;ldquo;Twitter&amp;rdquo; is the product of a combination of people and software, either or both of which can shift dramatically in a short period of time.&lt;/p></description></item><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item><item><title>Hacking LLM bots</title><link>https://dallascard.github.io/granular-material/post/remote-work-bot/</link><pubDate>Fri, 23 Sep 2022 10:39:28 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/remote-work-bot/</guid><description>&lt;p>For anyone who missed it, a Twitter account named @mkualquiera recently deployed what seems like a kind of adversarial attack in the wild on a large language model (LLM)-based Twitter bot. I&amp;rsquo;ll link to the key post below, but it&amp;rsquo;s worth providing a bit of context, as it wasn&amp;rsquo;t immediately clear to me what was going on when I first saw the tweet.&lt;/p>
&lt;figure>&lt;img src="../../img/remote-work-bot/header.png">
&lt;/figure></description></item><item><title>Report from FAccT 2022</title><link>https://dallascard.github.io/granular-material/post/facct-2022/</link><pubDate>Sun, 03 Jul 2022 12:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/facct-2022/</guid><description>The fifth iteration of FAccT (the ACM Conference on Fairness, Accountability, and Transparency) was held earlier this month (June 21â€“24) in Seoul, South Korea. More than just a hybrid conference, this was actually a full in-person conference, combined with a full on-line conference. These happened in parallel, with virtual sessions starting before and continuing after the in-person component each day. Around 500 people attended in person, with another 500 participating remotely.</description></item></channel></rss>