<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Granular Material</title><link>https://dallascard.github.io/granular-material/post/</link><description>Recent content in Posts on Granular Material</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 28 Mar 2025 23:55:54 -0400</lastBuildDate><atom:link href="https://dallascard.github.io/granular-material/post/index.xml" rel="self" type="application/rss+xml"/><item><title>Peeping Tom, Triptych</title><link>https://dallascard.github.io/granular-material/post/triptych/</link><pubDate>Fri, 28 Mar 2025 23:55:54 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/triptych/</guid><description>I don&amp;rsquo;t go to see much in the way of modern dance, but on a whim, I decided to get tickets to the Power Center to see &lt;em>Triptych&lt;/em>, a performance developed by the Peeping Tom dance company from Belgium. Comprised of three pieces&amp;mdash;&lt;em>The Missing Door&lt;/em>, &lt;em>The Lost Room&lt;/em> and &lt;em>The Hidden Floor&lt;/em>&amp;mdash;created in 2013, 2015, and 2017, respectively, the performance ran just over two hours, including a partial intermission. This post is a bit of a break from what I&amp;rsquo;ve been writing lately, but it feels worth highlighting, if only to help keep at least some attention on artistic endeavours. Just as a warning, I have not refrained from spoiling anything in here, so you might want to stop reading if you&amp;rsquo;re planning to see it and want the full effect.</description></item><item><title>Markets for Content</title><link>https://dallascard.github.io/granular-material/post/markets_for_content/</link><pubDate>Mon, 24 Mar 2025 13:09:22 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/markets_for_content/</guid><description>I don&amp;rsquo;t carefully track the numbers, bit it seems like various sectors of the media have been hit hard by layoffs recently. Earlier this month, Disney announced that it was shuttering FiveThirtyEight, the data journalism outlet that Nate Silver started what now feels like a lifetime ago. According to the Wall Street Journal, FiveThirtyEight only had a staff of about 15 people, but the move is part of a broader consolidation and job cuts at the company.</description></item><item><title>Force of Law</title><link>https://dallascard.github.io/granular-material/post/force-of-law/</link><pubDate>Mon, 10 Feb 2025 23:42:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/force-of-law/</guid><description>I do not feel particularly well qualified to write about this, but it seems to me that recent events have dramatically and urgently gestured at the nature of the rule of law, and the tenuousness of reliable enforcement. Since coming into office, the new administration has been carrying out actions that many legal experts suggest are illegal. In several cases since then, judges have issued orders which demand a pause on particular actions. Most recently, the New York Times reports that a judge has now ruled that the White House has failed to comply with a court order. While less splashy than various overt actions, this kind of failure act seems to me like to very close to the red line suggested by various commentators, including conservatives.</description></item><item><title>Chatbot Roulette</title><link>https://dallascard.github.io/granular-material/post/freysa/</link><pubDate>Sun, 08 Dec 2024 22:07:15 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/freysa/</guid><description>&lt;p>There was some excitement online recently around &lt;a href="https://x.com/jarrodWattsDev/status/1862299845710757980">&amp;ldquo;Freysa&amp;rdquo;&lt;/a>, a contest which combined large language models (LLMs) with some sort of blockchain technology. The basic idea was for participants to interact with an LLM to try to get it to do a thing that it had been instructed not to do. The trick was that the cost of each attempt increased after every submission (up to some maximum), as did the potential reward.&lt;/p></description></item><item><title>What is a Podcast?</title><link>https://dallascard.github.io/granular-material/post/sporc/</link><pubDate>Sat, 16 Nov 2024 19:34:55 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/sporc/</guid><description>What is a podcast? I expect we all have our own slightly idiosyncratic answer to that question. For me, podcasts are defined partly by some software I use on my phone that regularly downloads audio files from various feeds, which I periodically listen to, often as I&amp;rsquo;m doing other things. Most of these recordings feature two or more people engaged in a long-form conversation. Some of these take the form of interviews, in which a regular host interviews a rotating series of guests. Others feature rotating subsets of the same group of hosts, talking together about various issues. A few shows, like Hardcore History, are just long monologues, not so different from an audiobook.</description></item><item><title>Bespoke Navigation</title><link>https://dallascard.github.io/granular-material/post/bespoke-navigation/</link><pubDate>Sun, 29 Sep 2024 16:51:57 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/bespoke-navigation/</guid><description>&lt;p>I don&amp;rsquo;t normally do this, but I recently did a short bike trip in Michigan, and I thought I would write a brief post about it, in part because it cued various other ideas which have a more direct connection to the kinds of things I normally write about here.&lt;/p></description></item><item><title>Credible Estimates and Open Science</title><link>https://dallascard.github.io/granular-material/post/blair-institute/</link><pubDate>Tue, 30 Jul 2024 20:18:44 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/blair-institute/</guid><description>&lt;p>Somewhere on social media I encountered the recent story that the &lt;a href="https://www.institute.global/">Tony Blair Institute for Global Change&lt;/a>, (a large, avowedly centrist think tank created by Tony Blair), put out a &lt;a href="https://web.archive.org/web/20240709092248/https://assets.ctfassets.net/75ila1cntaeh/45YsrTDwevNRvsTsZ5dZGS/fc9805fa3a5a1de3c931d0446dcec239/Tony_Blair_Institute_for_Global_Change__The_Potential_Impact_of_AI_on_the_Public-Sector_Workforce__July_2024.pdf">report&lt;/a> estimating the potential impact of AI on jobs in the public service, but that ironically, they arrived at their estimates by basically just asking GPT-4. While this does have a certain kind of poetry to it, it&amp;rsquo;s not exactly what we think of as a reputable methodology.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p></description></item><item><title>Altair vs. Bokeh (part 3): Scatterplots</title><link>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_3/</link><pubDate>Sat, 22 Jun 2024 18:17:35 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_3/</guid><description>This is my third entry in a series comparing two interactive data visualization libraries for python, Bokeh and Altair. In part 1, I went through a basic overview of some of the differences in terms of syntactic style and defaults. In part 2, I went slightly deeper into some of the interactive features and more fundamental limitations. In this part, I want to deepen the comparison further, by exploring the basic capabilities each package offers with respect to a basic chart type, namely scatterplots.</description></item><item><title>The OpenAI Library</title><link>https://dallascard.github.io/granular-material/post/openai-library/</link><pubDate>Mon, 27 May 2024 12:52:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/openai-library/</guid><description>The New York Times recently ran a brief article about the reading room in OpenAI&amp;rsquo;s office in San Francisco. The article was heavy on images and light on text, but the overall theme was the tension between the company&amp;rsquo;s GPT models&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->which have been trained on vast swaths of human culture, and are therefore able to regurgitate, remix, and approximate it&lt;!-- raw HTML omitted -->—&lt;!-- raw HTML omitted -->versus embracing the design and aesthetic trappings of a traditional library reading room. The article mentioned a handful of books that could be found in the OpenAI library, but many more were clearly visible in the photographs that accompanied it.</description></item><item><title>Sociotechnical Considerations</title><link>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</link><pubDate>Sat, 27 Apr 2024 13:42:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/sociotechnical-considerations/</guid><description>&lt;p>A whole genre of podcasts seems to have emerged recently, taking the shape of interviews with CEOs of AI companies, or similar. Although I have not listened to many of these, they mostly seem to be pretty abysmal, both because of the amount of hype they involve, and due to the lack of meaningful specifics.&lt;/p>
&lt;p>That being said, of the ones I&amp;rsquo;ve heard, the recent &lt;a href="https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html">interview with Dario Amodei of Anthropic on the Ezra Klein Show&lt;/a> seems to me to be vastly better than the average. In part, this is because Klein is a smart, curious, and well informed interviewer, who asks a lot of the right questions, and pushes for details when responses get too mushy. In this case, it also helps that Amodei seems much more straightforwardly honest about limitations than most spokespeople in similar positions.&lt;/p></description></item><item><title>Financing Common Crawl</title><link>https://dallascard.github.io/granular-material/post/financing-common-crawl/</link><pubDate>Sun, 31 Mar 2024 20:08:01 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/financing-common-crawl/</guid><description>Mozilla recently published an excellent new report out about Common Crawl, the non-profit whose web crawls have played an important role in the development of numerous large language models (LLMs). Written by Stefan Baack and Mozilla Insights, the report is based on both public documents and new interviews with Common Crawl&amp;rsquo;s current director and crawl engineer, and goes into some detail about the history of the organization, and how its data is being used.</description></item><item><title>ChatGPT Prompt Speculations</title><link>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</link><pubDate>Thu, 22 Feb 2024 10:00:26 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt-prompt-speculations/</guid><description>In a recent tweet that went viral, Dylan Patel claimed to have discovered or revealed the ChatGPT prompt, using a simple hack. The tweet included a link to a text file on pastebin and a screenshot of that same text with newlines removed. More interestingly, the author suggested in a reply that anyone could replicate this finding, and a subsequent tweet included a video of ChatGPT generating text in response to the same trick. That, however, is where things get somewhat strange.</description></item><item><title>Infinitely Wide Culture</title><link>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</link><pubDate>Sun, 28 Jan 2024 15:59:40 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/infinitely-wide-culture/</guid><description>&lt;p>A lot of this is still unresolved in my mind, but I think there is something interesting happening at the intersection of generative AI, art, style, and entertainment. Rather than letting it gestate until more fully formed, I figured I&amp;rsquo;d just post some preliminary thoughts and come back to this at some later date.&lt;/p>
&lt;p>The main reason I&amp;rsquo;m thinking about this now is the ongoing debate about how generative AI will impact creative fields, such as writing and design (as well as white collar jobs more broadly). Arguably there have already been some pretty dramatic effects, such as the sci-fi magazine &lt;em>Clarkesworld&lt;/em> being &lt;a href="https://neil-clarke.com/a-concerning-trend/">suddenly overwhelmed&lt;/a> by spammy submissions. At the same time, it&amp;rsquo;s hard to know the extent to which these disruptions may end up being transient phenomena that broader systems will adapt to.&lt;/p></description></item><item><title>Tightly-woven Cultural Commentary</title><link>https://dallascard.github.io/granular-material/post/interwoven_commentary/</link><pubDate>Thu, 14 Dec 2023 21:57:32 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/interwoven_commentary/</guid><description>&lt;p>I recently started listening to the &lt;a href="https://www.artofthescore.com.au/">Art of the Score&lt;/a> podcast, which does an amazing job of unpacking movie soundtracks in depth, beginning with Raiders of the Lost Ark in the first episode. Like most such explorations of music, however, it ultimately leaves me wanting something that I&amp;rsquo;ve long thought there should be much more of&amp;mdash;namely, more tightly interwoven cultural commentary, especially for music. As I will describe below, I&amp;rsquo;m broadly interested in different ways of combining context, commentary, and criticism with the thing being commented on or critiqued.&lt;/p></description></item><item><title>Altair vs. Bokeh (part 2)</title><link>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_2/</link><pubDate>Mon, 27 Nov 2023 18:17:35 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_2/</guid><description>In the first part of this series, I used a basic bar plot to illustrate the differences between Altair and Bokeh in terms of defaults, chart configuration, and syntactic style. In this post, I&amp;rsquo;ll get into some of the more substantive differences, including more complicated chart types, combining plots, basic interactivity, and how to deploy the output online. Note that this is not intended to be a systematic comparison, but rather more of a preliminary exploration of the options.</description></item><item><title>Refik Anadol</title><link>https://dallascard.github.io/granular-material/post/refik-anadol/</link><pubDate>Wed, 25 Oct 2023 11:05:12 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/refik-anadol/</guid><description>&lt;p>Last week&amp;rsquo;s speaker in the &lt;a href="https://stamps.umich.edu/penny-stamps-speaker-series">Penny Stamps Speaker Series&lt;/a> was &lt;a href="https://en.wikipedia.org/wiki/Refik_Anadol">Refik Anadol&lt;/a>, one of the most successful artists working primarily with AI, data, and visualization. Over a decade or so, Anadol has produced work in collaboration with organizations and venues like the &lt;a href="https://refikanadol.com/works/visions-of-america-ameriques/">LA Philharmonic&lt;/a>, Gaudi&amp;rsquo;s &lt;a href="https://refikanadol.com/works/living-architecture-casa-batllo/">Casa Batlló&lt;/a>, &lt;a href="https://refikanadol.com/works/machine-hallucinations-sphere/">the Exosphere&lt;/a> in Las Vegas, and &lt;a href="https://refikanadol.com/works/unsupervised/">the Museum of Modern Art&lt;/a> in New York.&lt;/p>
&lt;p>The lecture he gave was basically a review of his body of work, and that of his art and design studio, which is comprised of about 20 people. The earlier projects he showed mostly took the form of massive scale &lt;a href="https://refikanadol.com/works/quadrature/">light projections&lt;/a> on the sides of buildings, which could give the impression of a totally different texture or form. More recent work tended to use data driven visualizations, abstracting some sort of data into visual patterns displayed on a wall, building, or screen. Many of these also made use of what appeared to be procedural animations to create the impression of three dimensionality and motion.&lt;/p></description></item><item><title>Ubi Sunt</title><link>https://dallascard.github.io/granular-material/post/ubi_sunt/</link><pubDate>Sun, 17 Sep 2023 13:05:18 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/ubi_sunt/</guid><description>&lt;p>There is a duality at the heart of large language models. On the one hand, they are essentially a backwards-looking invention, a &lt;a href="https://www.youtube.com/live/k7rPtFLH6yw?si=bD6ir6cwtpOtEV0i">&amp;ldquo;cultural technology&amp;rdquo;&lt;/a>, in the words of Alison Gopnik&amp;mdash;algorithms which index and remix a large slice of human culture (though one that is typically heavily biased towards the recent past). On the other hand, they can often seem to be producing something entirely new, and can thereby leave many people with the impression of having a personality or even &amp;ldquo;sentience&amp;rdquo; (whatever that means exactly); in the most extreme cases, &lt;a href="https://youtu.be/NgHFMolXs3U?si=gfKBPeOlEhQeDdEg">some people&lt;/a> have apparently convinced themselves that such models are a step on the path towards some sort of successor species to humanity, a new regime of algorithmic children that will survive our own human catastrophes. Complicating matters here is the fact that the emergence of and widespread attention to these systems largely overlapped with the Covid-19 pandemic, a time in which we have all had additional reason to reflect on life, death, loss, and creation.&lt;/p></description></item><item><title>University of Michigan's New AI Tools</title><link>https://dallascard.github.io/granular-material/post/michigan-gpt/</link><pubDate>Mon, 28 Aug 2023 21:04:19 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/michigan-gpt/</guid><description>Just before the start of the fall semester, the University of Michigan announced that it was launching a new suite of tools, all focused on &amp;ldquo;generative AI&amp;rdquo;, (although so far limited to language models), which will be available to all students, faculty, and staff. This post provides a preliminary exploration of the new offerings.</description></item><item><title>Altair vs. Bokeh (part 1)</title><link>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_1/</link><pubDate>Tue, 25 Jul 2023 18:17:35 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/altair_vs_bokeh_1/</guid><description>This is the first of what I hope will be a series of posts comparing Altair and Bokeh. Both are actively supported python packages for making interactive visualizations. This post will only scratch the surface, but is intended to show the basic differences in how they approach creating visualizations.</description></item><item><title>The Gradual Disappearance of Twitter</title><link>https://dallascard.github.io/granular-material/post/twitter-immolation/</link><pubDate>Sun, 11 Jun 2023 10:42:43 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/twitter-immolation/</guid><description>&lt;p>It was &lt;a href="https://inews.co.uk/news/twitter-researchers-delete-data-unless-pay-2364535">recently reported&lt;/a> by inews.co.uk that Twitter is going to start charging academic researchers and institution $42,000/month if they want to maintain their current level of expansive access to data, and &amp;ndash; more significantly &amp;ndash; require that they delete all Twitter data from their archives if they do not. I&amp;rsquo;d heard rumors that this might be happening a few weeks ago, but the iNews article is the first independent reporting that I&amp;rsquo;ve seen about it.&lt;/p></description></item><item><title>ChatGPT Hobbyists</title><link>https://dallascard.github.io/granular-material/post/mcgee/</link><pubDate>Mon, 29 May 2023 10:42:43 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/mcgee/</guid><description>&lt;p>ChatGPT has understandably garnered a huge amount of attention from all corners of academia, from philosophy to economics. One of the more quixotic examples I&amp;rsquo;ve encountered recently is &lt;a href="https://www.robertwmcgee.com/about/">Robert W. McGee&lt;/a>, and his many papers on this topic, such as &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4359405">&amp;ldquo;Is Chat Gpt Biased Against Conservatives? An Empirical Study&amp;rdquo;&lt;/a>.&lt;/p>
&lt;p>A professor of accounting at Fayetteville University, McGee&amp;rsquo;s biography reads as something like a Marvel Cinematic Universe version of a nerdy academic supervillain. In addition to having published 59 non-fiction books, McGee apparently holds 23 academic degrees, including 13 doctorates, as well as being a world champion in various martial arts, such as Taekwondo and Tai Chi.&lt;/p></description></item><item><title>Samsung's Encounter with ChatGPT</title><link>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</link><pubDate>Thu, 13 Apr 2023 19:48:46 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/samsung-chatgpt/</guid><description>&lt;p>As ChatGPT continues to ricochet through the news cycle, media outlets are surely on the hunt for new angles they can present to the public in order to keep this story in motion. Among other threads, one that has gained some traction is the question of risks to privacy and security presented by these new systems.&lt;/p>
&lt;p>Last week, a number of US outlets &lt;a href="https://mashable.com/article/samsung-chatgpt-leak-details">reported&lt;/a> on data leaks at Samsung, in which three employees (in separate incidents) apparently entered confidential company information into ChatGPT. According to &lt;a href="https://www.engadget.com/three-samsung-employees-reportedly-leaked-sensitive-data-to-chatgpt-190221114.html">reports&lt;/a>, in one case, an employee tried using ChatGPT to help debug code, another to optimize code, and a third to have it produce a summary of meeting notes.&lt;/p></description></item><item><title>ChatGPT and Sociotechnical Instability</title><link>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</link><pubDate>Sun, 19 Feb 2023 13:04:13 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt_and_instability/</guid><description>&lt;p>I&amp;rsquo;ve written about this &lt;a href="https://dallascard.github.io/granular-material/post/stability/">before&lt;/a>, but it&amp;rsquo;s worth remembering that almost nothing in sociotechnical systems is guaranteed to remain stable for very long. We&amp;rsquo;ve recently had two great examples of this, with the first being the changes to Twitter, and the second being ChatGPT (and, by extension, the new Bing).&lt;/p>
&lt;p>In the first case, a platform which had long seemed relatively static, (especially compared to all the rest), rather suddenly changed hands, which led to major changes in what it delivered. On some level, many of the technical changes to the actual functionality of the site were relatively minor. Much bigger, however, was the impact of many people abandoning the platform for alternatives like Mastodon. Although it seems to me like people have gradually been filtering back to Twitter, most people seem to have the sense that the experience has changed. Obviously more dramatic infrastructural changes, like prioritizing tweets from paying users, could produce even more dramatic shifts. Regardless, it&amp;rsquo;s a good reminder that what we think of as &amp;ldquo;Twitter&amp;rdquo; is the product of a combination of people and software, either or both of which can shift dramatically in a short period of time.&lt;/p></description></item><item><title>ChatGPT Dominance</title><link>https://dallascard.github.io/granular-material/post/chatgpt-dominance/</link><pubDate>Sat, 21 Jan 2023 14:39:35 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/chatgpt-dominance/</guid><description>&lt;p>I expect that almost anyone reading this will have heard of ChatGPT by now. Released about a month ago, ChatGPT is a system developed by OpenAI which provides text responses to text input. Although details are scarce, under the hood ChatGPT is basically a large language model, trained with some additional tricks (see Yoav Goldberg&amp;rsquo;s &lt;a href="https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9">write up&lt;/a> for a good summary). In other words, it is a model which maps from the text input (treated as a sequence of tokens), to a distribution over possible next tokens, and generates text by making repeated calls to this function, and sampling tokens from the predicted distributions.&lt;/p></description></item><item><title>AI, software, and governance</title><link>https://dallascard.github.io/granular-material/post/ai-software-governance/</link><pubDate>Mon, 12 Dec 2022 18:48:06 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-software-governance/</guid><description>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &amp;ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&amp;rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &amp;ldquo;breed&amp;rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&amp;rsquo;d like to focus on the term &amp;ldquo;A.I.&amp;rdquo; (henceforth &amp;ldquo;AI&amp;rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &amp;ldquo;AI&amp;rdquo;, as opposed to &amp;ldquo;models&amp;rdquo;, &amp;ldquo;programs&amp;rdquo;, &amp;ldquo;systems&amp;rdquo;, or other similar categories?</description></item><item><title>Hacking LLM bots</title><link>https://dallascard.github.io/granular-material/post/remote-work-bot/</link><pubDate>Fri, 23 Sep 2022 10:39:28 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/remote-work-bot/</guid><description>&lt;p>For anyone who missed it, a Twitter account named @mkualquiera recently deployed what seems like a kind of adversarial attack in the wild on a large language model (LLM)-based Twitter bot. I&amp;rsquo;ll link to the key post below, but it&amp;rsquo;s worth providing a bit of context, as it wasn&amp;rsquo;t immediately clear to me what was going on when I first saw the tweet.&lt;/p>
&lt;figure>&lt;img src="../img/remote-work-bot/header.png">
&lt;/figure></description></item><item><title>Report from FAccT 2022</title><link>https://dallascard.github.io/granular-material/post/facct-2022/</link><pubDate>Sun, 03 Jul 2022 12:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/facct-2022/</guid><description>The fifth iteration of FAccT (the ACM Conference on Fairness, Accountability, and Transparency) was held earlier this month (June 21–24) in Seoul, South Korea. More than just a hybrid conference, this was actually a full in-person conference, combined with a full on-line conference. These happened in parallel, with virtual sessions starting before and continuing after the in-person component each day. Around 500 people attended in person, with another 500 participating remotely.</description></item><item><title>Counting Deaths</title><link>https://dallascard.github.io/granular-material/post/counting-deaths/</link><pubDate>Sat, 14 May 2022 17:24:13 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/counting-deaths/</guid><description>Although morbid, it&amp;rsquo;s fascinating to read a recent article in the NYT about efforts in Sierra Leone to use &amp;ldquo;electronic autopsies&amp;rdquo; in a large scale attempt at counting deaths. According to the article, this undertaking is part of a broader effort at data collection, including questions on age, religion, marital status, etc. The novelty, it seems, is in trying to be thorough with respect to what people have died of (including extensive questions about symptoms), even though this information is being collected potentially long after the fact.</description></item><item><title>Modular Domain Adaptation</title><link>https://dallascard.github.io/granular-material/post/modular/</link><pubDate>Mon, 25 Apr 2022 20:16:54 -0400</pubDate><guid>https://dallascard.github.io/granular-material/post/modular/</guid><description>Despite their limitations, off-the-shelf models are still quite widely used by computational social science researchers for measuring various properties of text, including both lexicons, like LIWC, and cloud-based APIs, like Perspective API. The approach of using an off-the-shelf model has some definite advantages, including standardization and reproducibility, but such models may not be reliable when applied to a domain that differs from the ones on which they were developed&amp;hellip;</description></item><item><title>Stability and Change</title><link>https://dallascard.github.io/granular-material/post/stability/</link><pubDate>Sat, 12 Mar 2022 17:40:34 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/stability/</guid><description>&lt;p>One of the biggest frustrations with software is that things are constantly changing. From operating systems to apps to web interfaces, things rarely remain the same for very long, especially for users of Windows or MacOS.&lt;/p>
&lt;p>There are many reasons for this of course. For decades, hardware has continued to improve at a steady rate, and so software is constantly being rewritten to take advantage of the latest capabilities. Moreover, the incredibly sloppy standard for software quality and reliability (compared to traditional engineering disciplines) means that even the most professional software is shipped with massive numbers of bugs and vulnerabilities, which constantly need to be patched. This is a particularly large problem in institutional settings which are not set up for this pace of updates; some of the worst effects of the &lt;a href="https://www.theverge.com/2017/5/12/15630354/nhs-hospitals-ransomware-hack-wannacry-bitcoin">WannaCry&lt;/a> ransomware attack, for example, were on hospitals that were still using hopelessly out of date Windows machines.&lt;/p></description></item><item><title>Confidence in Science</title><link>https://dallascard.github.io/granular-material/post/confidence-in-science/</link><pubDate>Sun, 06 Mar 2022 09:20:14 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/confidence-in-science/</guid><description>&lt;p>I’ve been thinking recently about the role of confidence in science, and how long beliefs can persist simply because everyone else seems to believe them. Coincidentally, Andrew Gelman &lt;a href="https://statmodeling.stat.columbia.edu/2022/03/04/biology-as-a-cumulative-science-and-the-relevance-of-this-idea-to-replication/">posted&lt;/a> about this two days ago, responding to comments from a biologist about how the replication crisis had not been a major problem in biology. Her argument was that this was because biology is a &amp;ldquo;cumulative science&amp;rdquo;. By this she meant that when something important gets published, it is often the kind of discovery that people want to use immediately. If the original claims was wrong, people will quickly figure it out.&lt;/p></description></item><item><title>AI Dermatology: Part 2</title><link>https://dallascard.github.io/granular-material/post/ai-dermatology-2/</link><pubDate>Sat, 19 Feb 2022 16:26:43 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-dermatology-2/</guid><description>​In the last post, I discussed the possible broader implications of Google&amp;rsquo;s recent foray into making an AI dermatology tool. In this follow up post, I want to focus on the research behind the product announcement, bringing a slightly critical eye.</description></item><item><title>AI Dermatology: Part 1</title><link>https://dallascard.github.io/granular-material/post/ai-dermatology-1/</link><pubDate>Sat, 05 Feb 2022 07:32:51 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/ai-dermatology-1/</guid><description>&lt;p>Midway through last year Google &lt;a href="https://blog.google/technology/health/ai-dermatology-preview-io-2021/">announced&lt;/a> a new foray into the medical technology space, sharing that it was developing an &amp;ldquo;AI-powered dermatology assist tool&amp;rdquo;&amp;mdash;a phone-based app that would allow users to take photos of skin lesions and retrieve information about relevant medical conditions from the web. &lt;a href="https://www.skinvision.com/">Similar&lt;/a> &lt;a href="https://play.google.com/store/apps/details?id=com.aidermatologist&amp;amp;hl=en_US&amp;amp;gl=US">apps&lt;/a> already exist, but it&amp;rsquo;s fair to say that a comparable effort by Google is likely to have much more significant effects on how people interact with the medical system, their personal data, and even their own bodies.&lt;/p></description></item><item><title>Vaccine Allocation at Stanford Hospital</title><link>https://dallascard.github.io/granular-material/post/stanford-vaccines/</link><pubDate>Sat, 19 Dec 2020 21:43:54 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/stanford-vaccines/</guid><description>In a video that was widely shared last Friday, a representative from Stanford Medical Center spoke to residents protesting how the hospital chose to allocate its first shipment of COVID-19 vaccines. The hospital had around 5,000 initial doses to distribute (and expects to have tens of thousands more within the next few weeks), and came up with an allocation scheme in which only 7 of the approximately 1,300 residents were on the list. Many of these residents deal directly with patients who have COVID-19, whereas other more senior physicians, as well as other front line workers, such as nurses and food service employees, were given priority. In the video, the spokesperson explains that the algorithm they used to come up with an allocation scheme “clearly didn’t work”, to which protestors respond by shouting “Algorithms suck!” and “Fuck the algorithm!” &amp;hellip;</description></item><item><title>The case for professional critics in science</title><link>https://dallascard.github.io/granular-material/post/science-critics/</link><pubDate>Sat, 03 Oct 2020 21:24:17 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/science-critics/</guid><description>&lt;p>In many areas of science, there is an increasingly urgent unmet need, a role that could be simultaneously fascinating, rewarding, and potential remunerative. It is a role that already exists in various forms, but which could be made into something much more potent, especially if forces converged to make it more prominent. I am talking, of course, about the professional science critic.&lt;/p>
&lt;p>In the popular imagination, science operates something like a priesthood: scientists enter elite institutions as novices and emerge years later as full-fledged representatives of The Truth. Along the way, they are trained to be experts and professionals in their subject, to excel in action as well as in thought, and to sacrifice their worldly interests for the sake of their calling. The scholarly journals and peer review process are imagined to operate like an ecumenical council, guiding and filtering the thoughts of the broader community of the devout, and only allowing to pass what is deemed to be true and useful and good.&lt;/p></description></item><item><title>Representational Power</title><link>https://dallascard.github.io/granular-material/post/representational-power/</link><pubDate>Sat, 20 Jul 2019 21:27:37 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/representational-power/</guid><description>&lt;figure>&lt;a href="https://en.wikipedia.org/wiki/View_from_the_Window_at_Le_Gras">&lt;img src="../img/representational-power//plate.jpeg"
 alt="The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827.">&lt;/a>&lt;figcaption>
 &lt;p>The original plate of “View from the Window at Le Gras”, a heliograph made by Nicéphore Niépce around 1827.&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>Although it isn’t normally thought of in these terms, taking a photograph involves recording a four-dimensional block of space-time and projecting it down to a two-dimensional representation. With sufficiently sensitive material (and a fast enough shutter), one can produce images more or less instantaneously, but longer exposures reveal the inherent temporality of this process, showing us something that is clearly based on the world, yet quite different from our experience of it. Today, the ability to create images is so commonplace, of course, that we easily take it for granted, but early commentaries on photography reveal just how extraordinary it once was. Indeed, the history of photography provides both a compelling example of the power of representation, and a useful parallel to more recent forms of technological magic, especially that of machine learning.&lt;/p></description></item><item><title>On the Perils of Automated Face Recognition</title><link>https://dallascard.github.io/granular-material/post/face-recognition/</link><pubDate>Mon, 17 Dec 2018 21:59:04 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/face-recognition/</guid><description>&lt;figure>&lt;a href="https://commons.wikimedia.org/wiki/File:Bertillon,_Alphonse,_fiche_anthropom%C3%A9trique_recto-verso.jpg">&lt;img src="../img/face-recognition/bertillon.jpeg"
 alt="Anthropometric data sheet (both sides) of Alphonse Bertillon (1853–1914).">&lt;/a>&lt;figcaption>
 &lt;p>Anthropometric data sheet (both sides) of Alphonse Bertillon (1853–1914).&lt;/p>
 &lt;/figcaption>
&lt;/figure>

&lt;p>For anyone who has been paying attention, it will not have gone unnoticed that the past year has seen a dramatic expansion in the use of face recognition technology, including at schools, border crossing, and interactions with the police. Most recently, &lt;a href="https://news.delta.com/delta-unveils-first-biometric-terminal-us-atlanta-next-stop-detroit">Delta announced&lt;/a> that some passengers in Atlanta will be able to check in and go through security using only their face as identification. Most news coverage of this announcement emphasized the supposed convenience, efficiency, and technical novelty, while underplaying any potential hazards. In fact, however, the combination of widely available images, the ability to build on existing infrastructure, and a legal landscape that places very few restrictions on recording, means that face recognition represents a unique threat to privacy that should concern us greatly.&lt;/p></description></item><item><title>What everyone needs to know about interpretability in machine learning</title><link>https://dallascard.github.io/granular-material/post/interpretability/</link><pubDate>Fri, 25 May 2018 20:46:57 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/interpretability/</guid><description>For anyone who’s been paying attention, it should be apparent that statistical machine learning systems are being widely deployed for automated decision making in all kinds of areas these days, including criminal justice, medicine, education, employment, policing, and so on. Particularly with the recently enacted GDPR&amp;mdash;the new European regulation about data and privacy&amp;mdash;there is growing interest in having systems that are interpretable, that is, we can make some sense of why they are making the prediction that they are making. To borrow an example from Been Kim, if a computer tells you that you need surgery, you’re probably going to ask for some sort of explanation.</description></item><item><title>Privacy in Context</title><link>https://dallascard.github.io/granular-material/post/privacy-in-context/</link><pubDate>Mon, 14 May 2018 23:09:37 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/privacy-in-context/</guid><description>&lt;p>Although it was not the largest of its kind, or the most invasive, or even particularly surprising, the recent Cambridge Analytica scandal produced a surprisingly large amount of outrage and commentary. If nothing else, it was yet another reminder that we have gradually slipped into a regime where certain aspects of our privacy that could once be taken for granted are now long gone. Are people concerned? Is this something we should be worried about? What exactly are the harms that come from this sort of loss of privacy.&lt;/p></description></item><item><title>Emergent Archives</title><link>https://dallascard.github.io/granular-material/post/emergent-archives/</link><pubDate>Mon, 27 Nov 2017 22:12:15 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/emergent-archives/</guid><description>&lt;figure>&lt;img src="../img/emergent-archives/archives.jpg">
&lt;/figure>

&lt;p>It’s fascinating to think about how much we give to the internet, and sometimes, how much it gives back. In my mind, there is a fairly direct historical connection between self-archiving practices from a couple of decades ago (keeping a diary, making photo albums, writing letters, etc.), to all the more recent variations on this idea (status updates, tweets, photo feeds, etc.). The difference is arguably in how much of the background work is taken care of for us, and the fact that we now make so much of this information public or semi-public. While many have explored the implications of this for privacy, security, and surveillance, there is another aspect that gets less attention: the automatic creation of our own archives.&lt;/p></description></item><item><title>Montage as Archive</title><link>https://dallascard.github.io/granular-material/post/montage-as-archive/</link><pubDate>Sat, 25 Nov 2017 22:07:35 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/montage-as-archive/</guid><description>&lt;p>I was recently reminded of Christian Marclay’s &lt;a href="https://en.wikipedia.org/wiki/The_Clock_(2010_film)">&lt;em>The Clock&lt;/em>&lt;/a>&amp;mdash;a 24 hour film made up of thousands of short film clips, carefully edited together such that (when properly synchronized) the time depicted in each moment of film corresponds to the current time in the world. I’ve never seen it, and sadly only a few copies exist, but I think it’s a fascinating example of a kind of archival art.&lt;/p>
&lt;p>When you hear the description, you might think of it as just a kind of a gimmick, one which would not reward actual viewing. However, based on the (bootlegged) clips that are &lt;a href="https://kottke.org/13/06/about-an-hour-of-christian-marclays-the-clock">available online&lt;/a> and reports from various people who have seen it, it apparently achieves much more. To be clear, although many of the scenes involve a shot of some sort of time piece (thereby establishing the time in the source film), the composition is not so simple as just finding and assembling shots of clocks. Rather, we see a slice in time, sometimes with intercutting between films. As a result, common patterns quickly emerge: in the morning we get people waking up. In the evening, we see people eating dinner and attending parties, etc. This is interesting because what is shown in films bears some relation to what happens in the real world; even if it ends up being a distorted or idealized reflection, this certainly tells us something about how Hollywood depicts society, and by implication, something about society itself.&lt;/p></description></item><item><title>Reproducibility in Art and Science</title><link>https://dallascard.github.io/granular-material/post/reproducibility-in-art-and-science/</link><pubDate>Mon, 05 Jun 2017 20:43:20 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/reproducibility-in-art-and-science/</guid><description>&lt;p>Marking the beginning of a new &lt;a href="http://rhizome.org/editorial/2017/may/30/rhizome-google-partnership/">partnership&lt;/a> between Rhizome and the Google Cultural Institute, the Rhizome blog recently published a &lt;a href="http://rhizome.org/editorial/2017/may/30/preservation-by-accident-is-not-a-plan/">conversation&lt;/a> between Dragan Espenschied, Rhizome’s preservation director, and Vint Cerf, Google’s Chief Internet Evangelist. In addition to bringing together two people with among the coolest job titles ever, it got me thinking about some similarities between art and science when it comes to the issue of reproduction.&lt;/p>
&lt;p>The main thrust of the conversation is about the difficulty of preserving internet art. In particular, works such as &lt;a href="https://anthology.rhizome.org/the-web-stalker">The Web Stalker&lt;/a> were often made in a particular context, intended to be performances of a sort, and which depended on the existence of a certain technical infrastructure, including a particular operating system, a particular input device, an internet connection, and accompanying protocols. Part of the conversation relates to the fact that it’s actually very difficult to maintain or recreate every single thing that is required in order for a modern viewer to have the exact same experience as when it was first created. Nevertheless, Dragan argues, there is still value in preserving part of the experience.&lt;/p></description></item><item><title>The Self-Archiving machine</title><link>https://dallascard.github.io/granular-material/post/self-archiving-machine/</link><pubDate>Sun, 21 May 2017 20:47:34 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/self-archiving-machine/</guid><description>What lies in store for this post? As I write this, it exists in a strange space — not yet public, yet already part of an archive, of a kind. Perhaps it cannot yet even be properly called a post, (since it has not yet been posted), and yet it is there for me to read and edit, part of my collection of unpublished stubs, stored on the Medium servers along with who knows what metadata.</description></item><item><title>Elbow Room</title><link>https://dallascard.github.io/granular-material/post/elbow-room/</link><pubDate>Fri, 31 Mar 2017 20:52:03 -0500</pubDate><guid>https://dallascard.github.io/granular-material/post/elbow-room/</guid><description>&lt;figure>&lt;img src="../img/elbow-room/thinker.jpeg">
&lt;/figure>

&lt;p>Daniel Dennett is one of the most fascinating philosophers currently living. Although he pursued a traditional (but nonetheless exceptional) course of education, over time he seems to have moved farther and farther away from traditional philosophical methods and styles, and more toward a form of engagement that is simultaneously rigorous, original, and accessible. Not only is he prolific, he is far better informed on scientific topics than any other philosopher I can think of, and seems to have quite intentionally pursued a course through the relevant fields of inquiry in order to develop a sophisticated understanding of what we are as human beings.&lt;/p></description></item></channel></rss>