<!doctype html><html><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Why Write? - Granular Material</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><meta name=keywords content><link rel=canonical href=https://dallascard.github.io/granular-material/post/why-write/><link rel=stylesheet type=text/css href=https://dallascard.github.io/granular-material//css/combined-min.css></head><body><div class=site-wrap><header class="site-header px2 px-responsive"><div class="mt2 wrap"><div class=measure><a href=https://dallascard.github.io/granular-material/ class=site-title>Granular Material</a><nav class="site-nav right"><a href=https://dallascard.github.io/granular-material//tags/>Tags</a>
<a href=https://dallascard.github.io/granular-material//about/>About</a></nav><div class=clearfix></div></div></div></header><div class="post p2 p-responsive wrap" role=main><div class=measure><div class="post-header mb2"><h1 class=py2>Why Write?</h1><span class=post-meta>Sep 1, 2025</span><br></div><article class=post-content><p>If there is one question that I have returned to over and over in various hand-written journals, it is the basic question of why write anything at all. This could be taken to be asking myself why I am writing, or why others choose to write, or what the purpose or point of writing is more broadly. It could be a question about motivation, or impacts, or addiction. It could be a provocation, to myself or others. But the mystery remains. Why engage in this dangerous business?</p><p>Obviously there are many different ways of thinking about this. Many people have made a career out of writing, and are doing so primarily to earn income, either speculatively or contractually. For others, writing may be directed towards trying to persuade others, gain stature, or used as a way of sorting out their own thoughts. Perhaps most indirectly, writing may be aiming at inspiration&mdash;less trying to achieve any specific end, and more trying to interrupt or intervene on how oneself or others think.</p><p>This is an old question, of course, and one that writers in particular have frequently reflected on. Foucault, for example, wrote of an &ldquo;obligation&rdquo; to write, a sense that one could not avoid doing it without enduring anxiety or discomfort.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> Many others have similarly written about a compulsive need to write, the thing for some, one cannot not do. More recently, however, it seems clear that the development of modern language models has altered things in at least a few ways.</p><p>First is that the effective value of writing has changed dramatically since the release of ChatGPT. It is now far cheaper than it used to be to get a perfectly adequate (or possibly even great) essay on a topic of your choosing. It has long been the case that there has been far too much information on most topics for any one person to read. So in that sense, the sheer scale of writing isn&rsquo;t necessarily meaningfully different. On the other hand, we are now so used to seeing text produced by language models that it surely changes the way we approach text in general, perhaps gradually pushing us towards treating it as something more to be skimmed or summarized, rather than appreciated or enjoyed for its own sake.</p><p>The second is the flipside of the first: the fact that modern models are typically trained on texts for which authors have not explicitly and affirmatively opted in has reshaped what it means to put one&rsquo;s writing out into the world. For some, this seems to involve a combination of several issues, including fearing that your unique voice or style will be devalued, the possibility of having ideas falsely attributed to you, or simply not wanting to be indirectly contributing to a technology that one worries may be causing harm.</p><p>Interestingly, it seems like two highly divergent types of responses to this have emerged. On the one hand, some writers are seeking to protect their work ever more strongly. Vered Schwartz, for example, recently wrote a <a href=https://lostinautomatictranslation.com/blog/this-book-will-not-be-used-to-train-llms-1>post</a> about how the publisher of her new book (<em>Lost in Automatic Translation</em>) explicitly offered her the choice to opt in to licensing her work for model training, and offering compensation&mdash;with Vered choosing the alternative of opting out. As she writes, &ldquo;it seemed crazy to let LLMs train on it — allowing people to unknowingly plagiarize my book and risking the LLMs taking my words out of context and misrepresenting my ideas.&rdquo;</p><p>Other authors and publishers are involved in various lawsuits over such matters, and a number of famous writers have written <a href=https://www.theatlantic.com/books/archive/2023/08/ai-chatbot-training-books-margaret-atwood/675151/>editorials</a> on this topic. Given this reaction, I could imagine some authors moving towards something like small scale print runs of more literary works, as is more common for poetry, in a way that would offer some protection by obscurity. Alternatively, perhaps we will eventually create a modified legal system which would provide compensation to authors. But it seems hard to imagine that it would end up being anything other than a platform like Spotify, where most musicians seem to be ambivalent at best, and hostile at worst. Regardless, no matter what the law ends up as, there is an inherent tension here between wanting to retain control over the words one has put out into the world, and the desire to be widely read.<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p><p>At the opposite extreme, I have seen a number of people commenting that they are now explicitly writing partly, or perhaps even primarily, for future language models. For example, Tyler Cowen has started <a href=https://marginalrevolution.com/marginalrevolution/2025/02/writing-my-biography-autobiography.html>posting</a> a series of short biographical snapshots from different phases of his life on <em>Marginal Revolution</em>. In a <a href=https://marginalrevolution.com/marginalrevolution/2025/01/should-you-be-writing-for-the-ais.html>column</a> he wrote for Bloomberg, he argues &ldquo;If you wish to achieve some kind of intellectual immortality, writing for the AIs is probably your best chance. &mldr; If you want your grandchildren or great-grandchildren to know what you thought about a topic, the AIs can give them a pretty good idea&rdquo;. Similarly, Miles Osborne <a href=https://bsky.app/profile/maosbot.bsky.social/post/3liuah3bnu227>posted</a> earlier this year about how he and his co-authors want their machine learning textbook to be read by AIs, so as to more effectively help spread their ideas.</p><p>This is clearly a much more optimistic take, but it seems to me like both perspectives make some pretty strong assumptions about how the technology will continue to evolve. In both types of reactions, there is clearly a desire to have some effect on the world (providing an implicit answer to why write), but with Vered more focused on a near term impact, and Tyler thinking more about immortality. Personally, I find it hard to break away from something more like an open source mentality. One puts something out into the world, and it&rsquo;s perhaps best not to worry too much about what others might do with it, as that is in many ways largely outside of one&rsquo;s control.</p><p>Nevertheless, I want to conclude with three more reasons to write (there are always more), beyond the simple reason that it is important for thinking.</p><p>The first is that, at least in some domains, it still matters what certain people write, and how. Earlier this summer, the <em>New York Times</em> published an <a href=https://www.nytimes.com/interactive/2025/07/12/opinion/editorials/federal-judges-quotes-trump-administration.html>editorial</a> in which they republished excerpts from statements by dozens of federal judges in which they were ruling that various actions of the administration have been illegal. For example, they included quotes such as &ldquo;This is a path of perfect lawlessness, one that courts cannot condone&rdquo;, or &ldquo;The defendants’ Kafkaesque argument to the contrary would deprive the plaintiffs of any recourse under the law.” While many articles have reported on these individual decisions, the point here seems to be to emphasize not just the substance of the rulings, but something of the breadth, diversity, and flavour of the judges&rsquo; texts.</p><p>In other words, these remarks are attention worthy not just because of their potential legal ramifications, but because of their rhetorical power. Judges are perfectly capable of writing more plainly. But the power of these remarks comes from a combination of who they are coming from, and how they are written. Similarly styled text generated by a language model would not have the same import, and neither would more pedestrian remarks from the same people. Obviously not every statement by a judge or politician is of equal weight, but remarks such as these nevertheless demonstrate that, even today, words can have great power.</p><p>A second reason, and one that depends less on making things public, is building an archive for oneself of what and how you have thought about things over time. I am a compulsive scribbler, and have filled too many pages to ever revisit them in full. Creating a more &ldquo;official&rdquo; repository, such as a blog, provides at least somewhat of a curatorial function&mdash;filtering down to just some subset of thoughts, which may help to reveal more clearly how one&rsquo;s thinking evolves or mutates over time (or, as if often the case, stays surprisingly consistent at its core).</p><p>The final reason to point to, which has been especially on my mind lately, is simply that if one refrains from writing (or speaking or creating more broadly), one may relatively quickly lose the habit. There is no reason why that should need to be permanent, but much like going to the gym, starting up again is often much harder than maintaining a certain pace. (As I know from when I break the momentum of posting to this blog). There are clearly plenty of reasons today why we might choose to refrain from writing anything today, especially publicly, whether it is a feeling of fear, envy, embarrassment, or irrelevance. But if we stop writing, we may rather suddenly realize that we no longer quite remember how.</p><p>In the meantime, here is some more text for a future LLM to train on. Personally I don&rsquo;t think this will add much value to the training data, nor do I feel especially precious about limiting how it is used. But it does, I think, provide some value for me in terms of maintaining the habit, and in the best case, it perhaps could inspire others to do the same.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>From <em>Interview with Claude Bonnefoy</em> (1969). See the passage excerpted here: <a href=https://progressivegeographies.com/2011/07/29/foucault-on-writing-making-time-for-writing/>https://progressivegeographies.com/2011/07/29/foucault-on-writing-making-time-for-writing/</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>Another interesting example is the way that Reddit split over the decision to prohibit the use of Reddit posts for training models, with some redditors applauding the decision, and others leaving the site in protest.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article><div style=text-align:center><span class=post-meta></span></div><br><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/writing/>writing</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/archives/>archives</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/chatgpt/>chatgpt</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/data/>data</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/culture/>culture</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/accountability/>accountability</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/tyler-cowen/>tyler-cowen</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/michel-foucault/>michel-foucault</a></p><script src=https://utteranc.es/client.js repo=dallascard/granular-material issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script></div></div></div><footer class=footer><div class="p2 wrap"><div class="measure mt1 center"><nav class="social-icons icons"><a href=../../index.xml><img alt=RSS src=../../images/icons/rss.png></a>
<a href=https://twitter.com/dallascard><img src=../../images/icons/twitter.png alt=Twitter></a></nav><small>Copyright &#169; 2022<br>Powered by <a href=http://gohugo.io/ target=_blank>Hugo</a> & <a href=https://github.com/azmelanar/hugo-theme-pixyll target=_blank>Pixyll</a></small></div></div></footer><script src=../../js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-EL45TK68M9"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EL45TK68M9")</script></body></html>