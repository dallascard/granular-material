<!doctype html><html><head><meta name=generator content="Hugo 0.144.2"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Granular Material - Granular Material</title>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content><meta name=keywords content><link rel=canonical href=https://dallascard.github.io/granular-material/><link rel=stylesheet type=text/css href=https://dallascard.github.io/granular-material//css/combined-min.css></head><body><div class=site-wrap><header class="site-header px2 px-responsive"><div class="mt2 wrap"><div class=measure><a href=https://dallascard.github.io/granular-material/ class=site-title>Granular Material</a><nav class="site-nav right"><a href=https://dallascard.github.io/granular-material//tags/>Tags</a>
<a href=https://dallascard.github.io/granular-material//about/>About</a></nav><div class=clearfix></div></div></div></header><div class="post p2 p-responsive wrap" role=main><div class=measure><div class=home><div class=posts><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/chatgpt_and_instability/><p class="post-meta left">Feb 19, 2023</p><div class=clearfix></div><h3 class="h2 post-title">ChatGPT and Sociotechnical Instability</h3><p class=post-summary><p>I&rsquo;ve written about this <a href=https://dallascard.github.io/granular-material/post/stability/>before</a>, but it&rsquo;s worth remembering that almost nothing in sociotechnical systems is guaranteed to remain stable for very long. We&rsquo;ve recently had two great examples of this, with the first being the changes to Twitter, and the second being ChatGPT (and, by extension, the new Bing).</p><p>In the first case, a platform which had long seemed relatively static, (especially compared to all the rest), rather suddenly changed hands, which led to major changes in what it delivered. On some level, many of the technical changes to the actual functionality of the site were relatively minor. Much bigger, however, was the impact of many people abandoning the platform for alternatives like Mastodon. Although it seems to me like people have gradually been filtering back to Twitter, most people seem to have the sense that the experience has changed. Obviously more dramatic infrastructural changes, like prioritizing tweets from paying users, could produce even more dramatic shifts. Regardless, it&rsquo;s a good reminder that what we think of as &ldquo;Twitter&rdquo; is the product of a combination of people and software, either or both of which can shift dramatically in a short period of time.</p></p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/twitter/>twitter</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/sociotechnical-systems/>sociotechnical-systems</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/chatgpt/>chatgpt</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/instability/>instability</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/archives/>archives</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/chatgpt-dominance/><p class="post-meta left">Jan 21, 2023</p><div class=clearfix></div><h3 class="h2 post-title">ChatGPT Dominance</h3><p class=post-summary><p>I expect that almost anyone reading this will have heard of ChatGPT by now. Released about a month ago, ChatGPT is a system developed by OpenAI which provides text responses to text input. Although details are scarce, under the hood ChatGPT is basically a large language model, trained with some additional tricks (see Yoav Goldberg&rsquo;s <a href=https://gist.github.com/yoavg/59d174608e92e845c8994ac2e234c8a9>write up</a> for a good summary). In other words, it is a model which maps from the text input (treated as a sequence of tokens), to a distribution over possible next tokens, and generates text by making repeated calls to this function, and sampling tokens from the predicted distributions.</p></p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/chatgpt/>chatgpt</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/open-science/>open-science</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/evaluation/>evaluation</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/ai-software-governance/><p class="post-meta left">Dec 12, 2022</p><div class=clearfix></div><h3 class="h2 post-title">AI, software, and governance</h3><p class=post-summary>In a recent article covering the FTX collapse, the New York Times described large language models (LLMs) as &ldquo;an increasingly powerful breed of A.I. that can write tweets, emails and blog posts and even generate computer programs.&rdquo; There is a lot that we could pick apart in this definition (e.g., what makes LLMs part of a &ldquo;breed&rdquo;, what distinguishes the ability to write an email as opposed to a blog post, etc.), but for the moment I&rsquo;d like to focus on the term &ldquo;A.I.&rdquo; (henceforth &ldquo;AI&rdquo;). Referring to LLMs as an example of AI is certainly not atypical. Indeed, it increasingly seems like LLMs have become one of the modern canonical examples of this concept. But why is it that we think of these systems as members of this category? And how much rhetorical work is being done by referring to LLMs as a type of &ldquo;AI&rdquo;, as opposed to &ldquo;models&rdquo;, &ldquo;programs&rdquo;, &ldquo;systems&rdquo;, or other similar categories?</p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/artificial-intelligence/>artificial-intelligence</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/algorithmic-decision-making/>algorithmic-decision-making</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/governance/>governance</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/software/>software</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/sociotechnical-systems/>sociotechnical-systems</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/power/>power</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/remote-work-bot/><p class="post-meta left">Sep 23, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Hacking LLM bots</h3><p class=post-summary><p>For anyone who missed it, a Twitter account named @mkualquiera recently deployed what seems like a kind of adversarial attack in the wild on a large language model (LLM)-based Twitter bot. I&rsquo;ll link to the key post below, but it&rsquo;s worth providing a bit of context, as it wasn&rsquo;t immediately clear to me what was going on when I first saw the tweet.</p><figure><img src=../../img/remote-work-bot/header.png></figure></p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/twitter/>twitter</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/bots/>bots</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/sociotechnical-systems/>sociotechnical-systems</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/facct-2022/><p class="post-meta left">Jul 3, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Report from FAccT 2022</h3><p class=post-summary>The fifth iteration of FAccT (the ACM Conference on Fairness, Accountability, and Transparency) was held earlier this month (June 21–24) in Seoul, South Korea. More than just a hybrid conference, this was actually a full in-person conference, combined with a full on-line conference. These happened in parallel, with virtual sessions starting before and continuing after the in-person component each day. Around 500 people attended in person, with another 500 participating remotely.</p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/accountability/>accountability</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/algorithmic-decision-making/>algorithmic-decision-making</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/facct/>FAccT</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/face-recognition/>face-recognition</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/large-language-models/>large-language-models</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/science/>science</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/sociotechnical-systems/>sociotechnical-systems</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/counting-deaths/><p class="post-meta left">May 14, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Counting Deaths</h3><p class=post-summary>Although morbid, it&rsquo;s fascinating to read a recent article in the NYT about efforts in Sierra Leone to use &ldquo;electronic autopsies&rdquo; in a large scale attempt at counting deaths. According to the article, this undertaking is part of a broader effort at data collection, including questions on age, religion, marital status, etc. The novelty, it seems, is in trying to be thorough with respect to what people have died of (including extensive questions about symptoms), even though this information is being collected potentially long after the fact.</p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/data/>data</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/statistics/>statistics</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/quantification/>quantification</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/mortality/>mortality</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/archives/>archives</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/demography/>demography</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/biopolitics/>biopolitics</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/governmentality/>governmentality</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/michel-foucault/>Michel-Foucault</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/john-graunt/>John-Graunt</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/ian-hacking/>Ian-Hacking</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/modular/><p class="post-meta left">Apr 25, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Modular Domain Adaptation</h3><p class=post-summary>Despite their limitations, off-the-shelf models are still quite widely used by computational social science researchers for measuring various properties of text, including both lexicons, like LIWC, and cloud-based APIs, like Perspective API. The approach of using an off-the-shelf model has some definite advantages, including standardization and reproducibility, but such models may not be reliable when applied to a domain that differs from the ones on which they were developed&mldr;</p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/domain-adaptation/>domain-adaptation</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/measurement/>measurement</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/text-classification/>text-classification</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/lexicons/>lexicons</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/stability/><p class="post-meta left">Mar 12, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Stability and Change</h3><p class=post-summary><p>One of the biggest frustrations with software is that things are constantly changing. From operating systems to apps to web interfaces, things rarely remain the same for very long, especially for users of Windows or MacOS.</p><p>There are many reasons for this of course. For decades, hardware has continued to improve at a steady rate, and so software is constantly being rewritten to take advantage of the latest capabilities. Moreover, the incredibly sloppy standard for software quality and reliability (compared to traditional engineering disciplines) means that even the most professional software is shipped with massive numbers of bugs and vulnerabilities, which constantly need to be patched. This is a particularly large problem in institutional settings which are not set up for this pace of updates; some of the worst effects of the <a href=https://www.theverge.com/2017/5/12/15630354/nhs-hospitals-ransomware-hack-wannacry-bitcoin>WannaCry</a> ransomware attack, for example, were on hospitals that were still using hopelessly out of date Windows machines.</p></p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/archives/>archives</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/software/>software</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/wayback-machine/>wayback-machine</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/stability/>stability</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/change/>change</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/confidence-in-science/><p class="post-meta left">Mar 6, 2022</p><div class=clearfix></div><h3 class="h2 post-title">Confidence in Science</h3><p class=post-summary><p>I’ve been thinking recently about the role of confidence in science, and how long beliefs can persist simply because everyone else seems to believe them. Coincidentally, Andrew Gelman <a href=https://statmodeling.stat.columbia.edu/2022/03/04/biology-as-a-cumulative-science-and-the-relevance-of-this-idea-to-replication/>posted</a> about this two days ago, responding to comments from a biologist about how the replication crisis had not been a major problem in biology. Her argument was that this was because biology is a &ldquo;cumulative science&rdquo;. By this she meant that when something important gets published, it is often the kind of discovery that people want to use immediately. If the original claims was wrong, people will quickly figure it out.</p></p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/reproducibility/>reproducibility</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/invisible-colleges/>invisible-colleges</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/science/>science</a></p></div><div class=post><a class=post-link href=https://dallascard.github.io/granular-material/post/ai-dermatology-2/><p class="post-meta left">Feb 19, 2022</p><div class=clearfix></div><h3 class="h2 post-title">AI Dermatology: Part 2</h3><p class=post-summary>​In the last post, I discussed the possible broader implications of Google&rsquo;s recent foray into making an AI dermatology tool. In this follow up post, I want to focus on the research behind the product announcement, bringing a slightly critical eye.</p></a><p class=post-meta>Tags:&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/machine-learning/>machine-learning</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/dermatology/>dermatology</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/medicine/>medicine</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/reproducibility/>reproducibility</a>
,&nbsp;
<a href=https://dallascard.github.io/granular-material//tags/science/>science</a></p></div></div></div><div class=paginatin_area><div class="pagination clearfix mb1 mt4"><div class=left><a class=pagination-item href=../../page/2/>Newer</a></div><div class=right><a class=pagination-item href=../../page/4/>Older</a></div></div></div></div></div></div></div></div><footer class=footer><div class="p2 wrap"><div class="measure mt1 center"><nav class="social-icons icons"><a href=../../index.xml><img alt=RSS src=../../images/icons/rss.png></a>
<a href=https://twitter.com/dallascard><img src=../../images/icons/twitter.png alt=Twitter></a></nav><small>Copyright &#169; 2022<br>Powered by <a href=http://gohugo.io/ target=_blank>Hugo</a> & <a href=https://github.com/azmelanar/hugo-theme-pixyll target=_blank>Pixyll</a></small></div></div></footer><script src=../../js/highlight.pack.js></script><script>hljs.initHighlightingOnLoad()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-EL45TK68M9"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-EL45TK68M9")</script></body></html>